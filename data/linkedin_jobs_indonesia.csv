Title,Company,Location,URL,Description,skills_required
Data Scientist [Talent Pool all level],PT. Indosat Tbk,"Jakarta, Indonesia",https://id.linkedin.com/jobs/view/data-scientist-talent-pool-all-level-at-pt-indosat-tbk-4318330781?position=1&pageNum=0&refId=fi2obEXq7xy3%2BBJhqvwCPg%3D%3D&trackingId=CHGLd60ltXErryp%2FX%2FWzQw%3D%3D,"The Data Scientist plays a pivotal role in developing and operationalizing AI and machine learning solutions that address key business challenges across consumer, enterprise, and corporate domains. This role transforms complex business questions into analytical use cases, designs and trains predictive and prescriptive models, and ensures each model delivers measurable business outcomes such as churn reduction, ARPU growth, cost optimization, and customer satisfaction improvement. Beyond model creation, the Data Scientist leads the full AI lifecycle — from data exploration, feature engineering, and model development to testing, pipeline deployment, and continuous performance tracking. Each model is documented through Model Cards and deployed using Vertex AI pipelines (UDP to ACE) to ensure scalability, transparency, and compliance. By combining deep analytical expertise with Responsible AI practices, the Data Scientist ensures that every solution contributes to embedding AI as a strategic, value-generating capability across the organization Responsibilities Translate business needs into technical requirements and define model objectives, input data, and success metrics. Conduct exploratory data analysis (EDA), cleansing, transformation, and feature selection. Build, train, and test machine learning models aligned to business use cases and Responsible AI standards. Engineer new features to improve model performance and capture new business signals. Build, test, and maintain Vertex AI pipelines from UDP (Unified Data Platform) to ACE (AI CoE Environment). Maintain up-to-date model documentation including data lineage, assumptions, KPIs, and Responsible AI checks. Qualifications Bachelor’s or Master’s degree in Data Science, Statistics, Computer Science, or Applied Mathematics. 3–6 years of experience in machine learning model development and experimentation, ideally in telecom, fintech, or technology sectors. Strong proficiency in Python, SQL, and ML frameworks (TensorFlow, PyTorch, Scikit-learn). Experience working with cloud ML platforms (Vertex AI, AWS SageMaker, or Azure ML) and pipeline orchestration. Understanding of Responsible AI, bias testing, and model explainability principles. Strong communication and documentation skills for ARS and Model Card preparation.",aws;azure;communication;data scientist;eda;feature engineering;feature selection;machine learning;python;pytorch;scalability;scikit-learn;sql;tensorflow;testing;vertex ai
Data Scientist (AI Track),OCBC Indonesia,"Tangerang, Banten, Indonesia",https://id.linkedin.com/jobs/view/data-scientist-ai-track-at-ocbc-indonesia-4323171859?position=2&pageNum=0&refId=fi2obEXq7xy3%2BBJhqvwCPg%3D%3D&trackingId=yC43vjCOwtnOwX4TJ8ISlg%3D%3D,"OCBC Indonesia | Data Science Team | Jakarta, Indonesia Build the future of intelligent banking. On our own GPU clusters. You’re not just a data scientist. You’re an AI enabled data scientist who builds LLM-powered intelligence that actually works in the real world, especially in high-stakes financial environments. At OCBC Indonesia, you’ll design and deploy production-grade RAG systems that help operations, risk analysts, and customer service teams make faster, smarter, and more compliant decisions. And unlike most companies that rely on cloud APIs, you’ll work directly on our in-house GPU clusters , giving you rare, hands-on access to low-level AI infrastructure, distributed inference, and model optimization at scale. This is not a research lab. This is a high-impact AI team inside one of Southeast Asia’s most trusted banks , where your work directly reduces risk, accelerates loan approvals, and improves customer experience. All with full ownership and visibility. Key Responsibilities Design, build, and deploy production-grade RAG systems to enhance banking operations, customer support, and risk documentation. Integrating structured financial data with unstructured text (loan applications, contracts, regulatory docs, customer chats). Own end-to-end LLM-powered workflows : from query understanding and retrieval optimization to response generation, grounding, and post-processing. Ensuring outputs are accurate, compliant, and auditable. Develop and maintain robust evaluation frameworks (evals) to measure RAG performance across dimensions: relevance, faithfulness, answer correctness, latency, and hallucination rate, using both automated metrics (e.g., RAGAS, LLM-as-a-Judge) and human-in-the-loop validation. Collaborate with Data Engineering and MLOps to integrate RAG pipelines into production systems, leveraging vLLM for high-throughput, low-latency inference at scale. Apply prompt optimization frameworks like GEPA (Generative Evaluation and Prompt Architecture) to systematically improve LLM responses. Iterating on templates, chain-of-thought structures, and retrieval strategies based on eval feedback. Partner with Product, Risk, and Compliance to translate business needs into AI requirements. Drive A/B testing and offline/online evaluation of LLM-enhanced features, measuring uplift in approval rates, reduction in manual review time, or improvement in customer NPS. Minimum Qualifications Bachelor’s or master’s degree in computer science, statistics, mathematics, engineering , or a related quantitative field. 4+ years as a Data Scientist or ML Engineer in b anking, fintech, or financial services , with at least 1 year focused on LLMs and RAG systems . Strong proficiency in Python and core ML libraries, with experience in LLM orchestration frameworks . Proven hands-on experience designing, implementing, and evaluating RAG pipelines . including vector databases, embedding models, retrieval ranking, and response grounding techniques. Expertise in LLM evaluation frameworks . Building custom eval suites, defining metrics (e.g., precision@k, faithfulness, context relevance), and using tools like LangChain, LlamaIndex. Experience with end-to-end ML lifecycle : data wrangling, feature engineering, model training, offline/online evaluation, A/B testing, and production deployment. Ability to communicate complex AI concepts clearly to business, risk, and engineering teams, with a bias for clarity over jargon. Preferred Qualifications (A Plus!) Hands-on experience with vLLM for high-throughput LLM inference in production environments. Practical application of GEPA (Generative Evaluation and Prompt Architecture) or similar prompt optimization frameworks to systematically improve LLM performance. Experience with LLM fine-tuning (LoRA, QLoRA), instruction tuning, or distillation for domain-specific financial use cases. Familiarity with financial data domains : credit risk modeling, loan underwriting, KYC/AML documents, regulatory text, or financial NLP.",data engineering;data scientist;data wrangling;feature engineering;llm;mlops;nlp;python;rag;risk modeling;testing;vector databases
Frontend Developer,HJ Recruitment,Indonesia,https://id.linkedin.com/jobs/view/frontend-developer-at-hj-recruitment-4323045284?position=3&pageNum=0&refId=fi2obEXq7xy3%2BBJhqvwCPg%3D%3D&trackingId=wl0llc217V3cdhEJZ5uxYA%3D%3D,"Frontend Developer | Next.js | TypeScript | Remote We’re building something big a next-gen AI recruitment platform and we’re looking for a designer who can code .| Only applications who email and send me through projects will be considered - harvey.jutton@hjrecruiting.com This isn’t the usual “make it look pretty” design gig. You’ll own the look, feel, and flow of a platform that will be used by recruiters worldwide and you’ll build it with your own hands. If you love sketching interfaces, jumping straight into Next.js + TypeScript , and seeing your ideas go live fast, this role is for you. Why this role is different You won’t be “stuck in Figma.” You’ll design and code. You’ll have massive influence on how the product looks, feels, and scales. You’ll be working with a lean team that ships fast, experiments, and loves ideas. Your work will be seen, used, and appreciated by thousands of recruiters who rely on it. What you’ll be doing Design beautiful, modern, intuitive user interfaces Build them directly into production with Next.js + TypeScript Create a scalable design system that feels fresh and easy to use Turn complex workflows into smooth, simple user journeys Collaborate with product + backend to deliver at startup speed What we’re looking for A portfolio that shows taste, clarity, and modern design Real coding skills (Next.js, TypeScript, React) not just “basic HTML/CSS” SaaS or marketplace experience is a huge plus Someone creative, curious, and excited to push boundaries What’s in it for you Remote-first work from anywhere Equity be part of the upside, not just the day-to-day A chance to set the design tone for a global platform A fun, ambitious team that’s actually building something new not another copycat app If you’re a frontend developer, and you want to build something exciting with people who move fast, we’d love to see your portfolio and GitHub. If you’re ready to build AI that actually matters , send links to your projects and include 🦄 in your application . Email: harvey.jutton@hjrecruiting.com Only applications who email and send me through projects will be considered",css;github;html;react;typescript
Machine Learning Engineer [Talent Pool all LEvel],PT. Indosat Tbk,"Jakarta, Indonesia",https://id.linkedin.com/jobs/view/machine-learning-engineer-talent-pool-all-level-at-pt-indosat-tbk-4319200104?position=4&pageNum=0&refId=fi2obEXq7xy3%2BBJhqvwCPg%3D%3D&trackingId=blxggoeU4UvYwSzXOAzGvw%3D%3D,"Machine Learning Engineer (MLE) ensures that AI and machine learning models transition seamlessly from experimentation to production through well-structured, automated, and continuously improving pipelines. This role is responsible for code refactoring, CI/CD updates, pipeline monitoring in the experiment layer, and model retraining, ensuring AI systems are scalable, stable, and high-performing throughout their lifecycle. MLE ensures model code is production-ready, pipelines are automated and monitored, and models are retrained regularly to sustain accuracy and business value. The role combines strong engineering discipline with proactive problem-solving to make AI operationally reliable and value-generating across all domains of the AI CoE. Responsibilities: Refactor and modularize data science code for scalability, efficiency, and deployment readiness. Maintain and enhance CI/CD pipelines to automate model testing, packaging, and deployment. Monitor ML pipelines in Vertex AI experiment layer; ensure job completion, accuracy, and resource optimization. Execute scheduled or trigger-based retraining to maintain model performance and prevent drift. Manage code and pipeline versioning; update documentation and logs after every retrain or release. Partner with Data Scientists and MLE Ops to troubleshoot deployment or retraining issues. Qualifications: Bachelor’s degree in Computer Science, Data Engineering, or Artificial Intelligence. 5–8 years of experience in machine learning engineering, MLOps, or AI deployment environments. Proficient in Python, Git, and cloud ML platforms such as Vertex AI (GCP) or equivalent (AWS SageMaker, Azure ML). Strong experience in CI/CD pipeline automation and code optimization for production deployment. Understanding of model retraining workflows, monitoring, and data drift detection. Excellent problem-solving, documentation, and collaboration skills in agile, cross-functional teams.",agile;aws;azure;ci/cd;data engineering;gcp;git;machine learning;mlops;monitoring;python;scalability;testing;vertex ai
"Data Scientist, Business Intelligence",Shopee,"Jakarta, Indonesia",https://id.linkedin.com/jobs/view/data-scientist-business-intelligence-at-shopee-4320394831?position=5&pageNum=0&refId=fi2obEXq7xy3%2BBJhqvwCPg%3D%3D&trackingId=cvm4hlQuKFocpNDYDuUQ%2BQ%3D%3D,"Job Description Prototyping, developing, and deploying advanced analytics data models and machine learning solutions. Communicating with the product and business teams to understand business processes and translate them to modeling requirements. Researching industry trends and competition information, analyze the change trend of user demands, and diagnose business problems through multi-dimensional analysis, discovering risks, excavation opportunities & providing optimization. Requirements Master's or Bachelor's degree in Science, Technology, Engineering dan Mathematics or a relevant field of study Min. 1 year of relevant experience in Data Science or similar fields. Advanced knowledge in Python/R is essential and working knowledge of SQL is strongly preferred. Familiarity in Natural Language Processing / Deep Learning specific algorithms is a plus (e.g. NLTK, SKLearn, TensorFlow).",deep learning;machine learning;natural language processing;python;r;sklearn;sql;tensorflow
Data Scientist,Prudential Indonesia (PT Prudential Life Assurance),"Jakarta, Indonesia",https://id.linkedin.com/jobs/view/data-scientist-at-prudential-indonesia-pt-prudential-life-assurance-4323334499?position=6&pageNum=0&refId=fi2obEXq7xy3%2BBJhqvwCPg%3D%3D&trackingId=kJvsnj6p%2BV2t%2Bb8q9IAmIw%3D%3D,"Prudential’s purpose is to be partners for every life and protectors for every future. Our purpose encourages everything we do by creating a culture in which diversity is celebrated and inclusion assured, for our people, customers, and partners. We provide a platform for our people to do their best work and make an impact to the business, and we support our people’s career ambitions. We pledge to make Prudential a place where you can Connect, Grow, and Succeed. Job Responsibilities: Design, build, and maintain analytics solutions that enable data-driven decision-making across internal business teams. Optimise and maintain code for accuracy, performance, scalability, and maintainability across the full analytics pipeline – from data extraction to modelling, visualisation, and user interfaces. Collaborate closely with markets and end users to plan, develop, and deliver impactful, user-centric solutions. Requirements: At least 5 years of experience in analytics, data science, data engineering or a related field. Proficiency in Python, SQL, PowerBI, and DAX. Experience in insurance industry data analytics is highly advantageous. Passion for solving complex business problems using quantitative approaches. Bachelor’s degree or higher in Statistics, Computer Science, Actuarial Science, Mathematics, Business Analytics, Economics, or a related quantitative field. Prudential is an equal opportunity employer. We provide equality of opportunity of benefits for all who apply and who perform work for our organisation irrespective of sex, race, age, ethnic origin, educational, social and cultural background, marital status, pregnancy and maternity, religion or belief, disability or part-time / fixed-term work, or any other status protected by applicable law. We encourage the same standards from our recruitment and third-party suppliers taking into account the context of grade, job and location. We also allow for reasonable adjustments to support people with individual physical or mental health requirements.",business analytics;data engineering;powerbi;python;scalability;sql
Front-end Developer,Faspay,"Sawah Besar, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/front-end-developer-at-faspay-4336871434?position=7&pageNum=0&refId=fi2obEXq7xy3%2BBJhqvwCPg%3D%3D&trackingId=3RTX9vWN2aN0IKwF70mdww%3D%3D,"Job Qualifications Bachelor’s degree in Computer Science, Information Technology, or related field. 2–3 years of experience as a Front End Engineer/Developer, preferably in fintech, e-commerce, or payment gateway industry. Strong proficiency in HTML5, CSS3, and JavaScript (ES6+). Hands-on experience with modern front-end frameworks such as React.js, Next.js, or Vue.js. Proficient in integrating RESTful APIs / GraphQL. Familiar with version control systems (Git/GitHub/GitLab). Solid understanding of responsive design and cross-browser compatibility. Knowledge of secure coding practices for financial and payment applications. Experience with build and packaging tools (Webpack, Vite, or similar). Job Descriptions Build, develop, and maintain high-performance, secure, and responsive web-based payment gateway applications. Translate UI/UX designs into interactive, user-friendly web applications. Optimize applications for speed, accessibility, and cross-browser compatibility. Collaborate with Product Managers, Backend Engineers, and UI/UX Designers to deliver new features. Ensure front-end security (e.g., XSS, CSRF protection, input validation) in compliance with fintech/payment standards. Integrate the front end with backend APIs and third-party services (e.g., payment methods, fraud detection, etc.). Create and maintain technical documentation for front-end development. Stay up to date with the latest front-end technologies and best practices to enhance product quality.",fraud detection;git;github;gitlab;graphql;javascript;react;security;version control;vue
Machine Learning Operation Engineer [Talent Pool all Level],PT. Indosat Tbk,"Jakarta, Indonesia",https://id.linkedin.com/jobs/view/machine-learning-operation-engineer-talent-pool-all-level-at-pt-indosat-tbk-4318330846?position=8&pageNum=0&refId=fi2obEXq7xy3%2BBJhqvwCPg%3D%3D&trackingId=tMwWmw48wKTvOwprxBoPug%3D%3D,"Machine Learning Engineer – Ops (MLE Ops) ensures the continuous operation, performance, and reliability of AI and machine learning models that have been deployed into production. This role manages the daily execution of ML pipelines, monitors model performance in the experiment and production layers, and supports retraining, version control, and issue resolution to maintain model health and value realization. As part of the AI CoE’s Run Layer, the MLE Ops is responsible for ensuring that all AI systems deployed through Vertex AI are stable, auditable, and continuously optimized. The role involves close collaboration with MLEs, Data Scientists, and FinOps Analysts to monitor costs, model drift, and performance degradation, ensuring AI remains an operationally reliable capability across all domains. Responsibilities: Monitor and manage AI pipelines in Vertex AI; ensure job completion, version tracking, and failure recovery. Monitor deployed models for data drift, accuracy decay, and performance anomalies. Execute scheduled or trigger-based model retraining to sustain performance levels. Ensure continuous integration pipelines run smoothly; apply updates and patches as needed. Diagnose and resolve pipeline, model, or data-related incidents in coordination with MLEs and Data Engineers. Maintain logs, change records, and performance reports for governance and transparency. Qualifications: Bachelor’s degree in Computer Science, Information Technology, or Data Engineering. 3–6 years of experience in machine learning operations (MLOps), DevOps, or data infrastructure management. Hands-on experience with Vertex AI, Airflow, Docker, and CI/CD frameworks (GitLab CI, Jenkins, Cloud Build). Understanding of model monitoring, retraining workflows, and performance metrics tracking. Strong analytical and troubleshooting skills for debugging complex pipeline or environment issues. Detail-oriented with good documentation habits and a focus on operational discipline.",airflow;ci/cd;data engineering;devops;docker;gitlab;gitlab ci;jenkins;machine learning;mlops;monitoring;version control;vertex ai
Gojek - Data Scientist - Supply incentives,GoTo Group,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/gojek-data-scientist-supply-incentives-at-goto-group-4310705375?position=9&pageNum=0&refId=fi2obEXq7xy3%2BBJhqvwCPg%3D%3D&trackingId=%2BQU%2BIsmNmhZ8ABOMkE%2FcSA%3D%3D,"About The Role As a Data Scientist on the Fulfilment team at Gojek, you’ll join a cross-functional group spanning Singapore, India, and Indonesia, working together to solve some of the company’s most complex and impactful problems. Our mission is to fulfil our users' orders efficiently and balance the needs of the customers, drivers and merchants. In this role, you’ll work closely with business leaders, product managers, engineers, and fellow data scientists who are deeply committed to building real-world solutions. Within your first six months, you’ll contribute to improving our dynamic driver incentives to drive reliability of our on demand services. This is a high-impact role where core data science work directly shapes the user experience and driver earnings. If you're passionate about using data to solve real problems, thrive in a fast-moving environment, and want to see your work make a tangible difference at scale, this is the team for you. What You Will Do Translate complex business challenges into well-defined technical problems solvable with data, statistics, and machine learning. Collaborate with product managers, engineers, and business stakeholders to build and scale data science solutions that power driver allocations, surge pricing and driver incentives. Own the full ML lifecycle—from ideation and research to model development, pipeline implementation, deployment, experimentation, and driving measurable business outcomes. Improve the efficiency of our dynamic driver incentives using techniques from machine learning, causal inference, optimisation and simulation Design and interpret experiments to measure model impact, working with analysts and product teams to ensure rigorous evaluation and clear success metrics. Monitor and evaluate model performance, identifying areas for improvement and proposing solutions Communicate insights, trade-offs, and technical decisions effectively to cross-functional stakeholders, and operate with a high degree of autonomy in ambiguous problem spaces. What You Will Need Bachelor’s or Master’s degree in Computer Science, Statistics, Machine Learning, or a related quantitative field Solid understanding of statistics and machine learning fundamentals, with coursework or projects demonstrating practical application. Proficiency in Python and SQL, and familiarity with data analysis or modeling libraries. Strong analytical thinking and problem-solving skills, with the ability to reason from data and communicate findings clearly. A willingness to learn fast, take initiative, and work collaboratively in a cross-functional team. Curiosity, humility, and a drive to apply data science to real-world problems at scale. About The Team The fulfilment team works on some of the most high-leverage problems in Gojek. Our real time engines power all of Gojek's on demand services - food delivery, ride-hailing and logistics - and ensure the timely fulfilment of millions of orders daily. We tackle complex, real-world challenges: What’s the best driver incentive scheme given budget and supply targets? How can pricing be adjusted to maximize revenue as well as balance customer demand and driver earnings? Why are drivers with certain characteristics more likely to complete long-distance trips than others? How long will a certain food order take for a restaurant to prepare and accordingly when should we dispatch a driver? And how do we take these decisions in real time, just a few milliseconds? Solving these problems requires not just data and models, but thoughtful product design, experimentation, and scale. We’re equipped with rich datasets, strong cross-functional partnerships, and modern MLOps infrastructure to build and deploy impactful solutions efficiently. As a team, we’re concerned not only with the growth of the company, but each other’s personal and professional growths, too. Along with keeping fit (via table tennis or other activities), our team bonds over our shared love of traveling and eating. About GoTo Group GoTo Group is the largest digital ecosystem in Indonesia with its mission to “Empower Progress’ by offering technological infrastructure and solutions for everyone to access and thrive in the digital economy. The GoTo ecosystem consists of on-demand transportation services, food and grocery delivery, logistics and fulfillment, as well as financial and payment services through the Gojek and GoTo Financial platforms.It is the first platform in Southeast Asia that hosts these crucial cases in a single ecosystem, capturing the majority of Indonesia’s vast consumer household. About Gojek Gojek is Southeast Asia’s leading on-demand platform and pioneer of the multi-service ecosystem with over 2.5 million driver partners across the regions offering a wide range of services such as transportation, food delivery, logistics and more. With its mission to create impact at scale, Gojek is committed to resolving consumer problems and raising standards of living by connecting consumers to the best providers of goods and services in the market. About GoTo Financial GoTo Financial accelerates financial inclusion through its leading financial services and merchants solutions. Its consumer services include GoPay and GoPayLater and serve businesses of all sizes through Midtrans, Moka, GoBiz Plus, GoBiz, and Selly. With its trusted and inclusive ecosystem of products, GoTo Financial is open to new growth opportunities and aims to empower everyone to Make It Happen, Make It Together, Make It Last. GoTo and its business units, including Gojek and GoToFinancial (""GoTo"") only post job opportunities on our official channels on our respective company websites and on LinkedIn. GoTo is not liable for any job postings or job offers that did not originate from us. You should conduct your own due diligence to prevent being victims of any fake job scams, if they did not originate from GoTo's official recruitment channels.",data scientist;machine learning;mlops;python;sql
Data Scientist,Blue Bird Group,"Jakarta, Indonesia",https://id.linkedin.com/jobs/view/data-scientist-at-blue-bird-group-4336926240?position=10&pageNum=0&refId=fi2obEXq7xy3%2BBJhqvwCPg%3D%3D&trackingId=ru7I%2FjSG5%2BWp%2F8Y7ih5vxA%3D%3D,"Job Qualifications: Bachelors degree in Computer Science, Statistics, Mathematics, Data Science, or related field (Masters degree is a plus). Strong knowledge of supervised and unsupervised ML algorithms and statistical concepts. Proficiency in SQL and Python for data wrangling and preprocessing. Hands-on experience with forecasting models and time-series analysis (ARIMA, XGBoost, CatBoost, Prophet, LSTM). Familiarity with ETL pipelines, model deployment (Docker, APIs), and MLOps practices. Experience with cloud environments (AWS, GCP) and data visualization tools. Excellent analytical, problem-solving, and communication skills; ability to work collaboratively in a team environment. Key Responsibilities: Develop and evaluate forecasting models using statistical and machine learning techniques. Contribute to model generation and optimization using ML algorithms. Perform data exploration and analysis (EDA) for feature engineering. Collaborate with operations teams to translate findings into actionable strategies. Design and maintain ETL pipelines for data processing. Deploy machine learning models into production environments and ensure ongoing maintenance using MLOps practices. Work with cloud platforms (AWS, GCP) for scalable model deployment. Ensure data integrity and quality throughout the pipeline.",arima;aws;catboost;communication;data visualization;data wrangling;docker;eda;etl;feature engineering;gcp;lstm;machine learning;mlops;model deployment;python;sql;xgboost
AI ML Engineer,STEDI Talent Solution,Indonesia,https://id.linkedin.com/jobs/view/ai-ml-engineer-at-stedi-talent-solution-4337975102?position=1&pageNum=2&refId=fA9FObB2cvwGbuRyT9SR8A%3D%3D&trackingId=St5w8sDO%2B7STLHZis9c1Rw%3D%3D,"About the Company Our client is an US-based software aggregator that uses AI and machine learning solutions. About the Role Our client is looking for a Machine Learning Engineer who’s passionate about solving real-world data and spatial analysis problems. In this role, you’ll work on end-to-end ML solutions — from data parsing and structuring to building robust visualizations and intelligent automation tools. You’ll join a team that values clear thinking, experimentation, and clean code. Our projects use real production data, where accuracy, efficiency, and explainability truly matter. Responsibilities Design and implement clean, modular Python solutions for data processing and analysis. Work on real-world spatial or image-based problems using modern tools and frameworks. Validate models and results through logical, transparent reasoning. Collaborate with cross-functional teams to turn data insights into practical outcomes. Communicate technical concepts clearly, including trade-offs and debugging strategies. Qualifications Familiarity with AI-assisted development tools (e.g., Copilot, Cursor) is a must Min 5 years of relevant experience Excellent English communication skill Strong proficiency in Python 3.11+ (typing, pathlib, etc.). Hands-on experience with libraries such as PyMuPDF, OpenCV, and Shapely (or similar). Proven ability to analyze documents, images, or structured data. Curiosity, adaptability, and a growth mindset. Indonesian Citizen If you thrive in a demanding, fast-paced environment and are looking for a truly rewarding experience, this could be the place for you.",communication;machine learning;opencv;python
ML Engineer,ilmuOne Data,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/ml-engineer-at-ilmuone-data-4315132644?position=2&pageNum=2&refId=fA9FObB2cvwGbuRyT9SR8A%3D%3D&trackingId=c4lDQs81eG%2BDfRfFyFuEEQ%3D%3D,"The Role You will be responsible for : Design, develop, test, deploy, maintain and optimize ML models/infrastructure and software that uses these models. Architect efficient and scalable systems that drive complex applications. Build the libraries and frameworks that support large, complex web applications. Contribute to engineering efforts from planning and organization to execution and delivery to solve complex, real world engineering problems. Identify and resolve performance and scalability issues. Participate in cutting edge research in artificial intelligence and machine learning applications. Manage individual project priorities, deadlines and deliverables. Ideal Profile Bachelor's degree in Computer Science, Data Science, Machine Learning or equivalent work experience. 1-3 years of relevant work experience in machine learning software development and architectures for machine learning (with focus on deep learning, computer vision, LLMs, GNN, RL. 1-3 years of experience using Python and popular libraries such as Scikit-learn, TensorFlow, or PyTorch. Experience designing and implementing distributed software systems (e.g Java, C++, or Python). Experience improving quality through thoughtful code reviews, appropriate testing, proper rollout, monitoring, and proactive changes. Experience with deployment on cloud platforms: AWS, Azure, GCP. Experience with developing machine learning models at scale from inception to business impact. Excellent communication skills and the ability to work in a team-oriented environment. Experience building maintainable and testable code bases, including API design and unit testing techniques What's on Offer? Excellent career development opportunities Flexible working options Great work environment",api design;aws;azure;c;communication;computer vision;deep learning;gcp;java;machine learning;monitoring;python;pytorch;scalability;scikit-learn;tensorflow;testing;unit testing
Applied Data Scientist,Taskify AI,Indonesia,https://id.linkedin.com/jobs/view/applied-data-scientist-at-taskify-ai-4338413115?position=3&pageNum=2&refId=fA9FObB2cvwGbuRyT9SR8A%3D%3D&trackingId=giznnT3DesR4eNEMNpWTgA%3D%3D,"Role: Applied Data Scientist Location: Remote We are hiring applied data science professionals to drive a high-impact analytics initiative. In this short-term contract role, you’ll work with complex datasets to uncover insights, build statistical models, and guide business decisions — without the overhead of production ML engineering. What You’ll Do Convert business questions into clear analytical workflows Perform data wrangling, EDA, and hypothesis testing Build statistical models and predictive tools Develop dashboards and visualizations for business teams Communicate findings to non-technical stakeholders What You Bring 5+ years in applied data science or analytics Strong Python or R skills (pandas, NumPy, Jupyter) and solid SQL experience Familiarity with BI tools like Tableau or Power BI Strong foundation in statistics, experimentation, and A/B testing Excellent communication and storytelling abilities Role Details Remote ~6-week project Minimum 30 hours/week Compensation $75–$100 per hour Weekly payments Independent contractor role Apply Now!",communication;data scientist;data wrangling;eda;hypothesis testing;numpy;pandas;python;r;sql;tableau;testing
Sr Data Scientist,Amar Bank,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/sr-data-scientist-at-amar-bank-3834482838?position=4&pageNum=2&refId=fA9FObB2cvwGbuRyT9SR8A%3D%3D&trackingId=3YF9ZSV7RQnaiFKzGc1oNg%3D%3D,"Who are we? Amar Bank is one of the most technologically advanced digital banks in Indonesia. Our leading digital lending product, Tunaiku has the distinction of being the first FinTech product in Indonesia. We are also the first digital bank on the cloud. As the first profitable digital bank, we managed to get listed on the Indonesian Stock Exchange. How did we manage to do that? We are changing people’s perception of a bank. We believe we are the innovators who combine customer focus principles with creating technology-based impact. We incorporate freedom and flexibility as part of our startup working culture DNA to encourage innovation in creating better financial solutions for the banking industry. We think of ourselves as, ‘A technology company with a banking license’. For this reason, we ‘Act like a FinTech, and think like a Bank.’ How did it all start? Founded on March 15, 1991, in Surabaya as PT Anglomas International Bank (Amin Bank), the bank was acquired by Tolaram Group and transformed to PT Bank Amar Indonesia (Amar Bank) in 2014. It has then undergone a significant digital transformation to become one of the country's forerunning fintech institutions through its award-winning digital lending platform, Tunaiku. Our philosophy, mission, and vision Technology must impact lives, must improve lives. We exist to provide banking to those who ‘need’ and not only to those who ‘want’. Services when provided to those who need at the time of their need brings smiles. Our vision is to bring 200 million smiles. More About The Bank With Startup Culture Environment Consist of 1000+ people, you will meet people who love to grow, dream big, and actually have fun at the workplace! We provide a great working environment that pushes people to grow outside their comfort zone. People with high drive and ambition find us a very attractive place to work as their career growth matches their own drive and not any staid policies. Thus we hold the honor of being awarded “Best Place to Work in Indonesia”. Recently Amar Bank was awarded as Inspirational Brand from APEA (Asia Pacific Enterprise Awards) 2022. Of course, our innovation won't stop here. So if you would love to be a part of it, have a growth mindset, and are constantly hungry for challenges, we invite you to join us in our journey to ‘Impact Lives’. Join us today and create #unlimitedinnovations! Responsibilities Model Selection and Optimization: involved in selecting advanced models, optimizing hyperparameters, and improving model performance Leadership: lead projects, guide junior team members, and provide strategic input on data science initiatives Decision-Making: making decisions on the overall data science strategy and direction for the organization Complex Problem Solving: tackling more complex and nuanced business problems using advanced analytical techniques Collaboration and Communication: interacting with cross-functional teams and stakeholders to understand business goals and translate them into data science solutions Requirements Education: master's or Ph.D. in a quantitative field with several years of relevant work experience Experience: proven track record of successful data science projects and a deep understanding of various machine learning algorithms Advanced skills: proficiency in advanced statistical methods, deep learning, and other complex analytical techniques (modeling with R, Python, SQL, or similar tools) Business acumen: understanding of the business context and the ability to align data science initiatives with organizational goals Communication skills: strong communication skills in English to explain complex concepts to non-technical stakeholders Bonus Point If Prior working experience from banking sector, especially from area of debt collection We exist to innovate and maintain the architecture of Amar Bank's products. As part of our main focus to create through technology we ensure the process and technology we use helps maintain and build human connection at scale. It’s our job to plan, monitor, and control the technology growth so we can provide a faster, more convenient, and more efficient way of performing business transactions. We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.",communication;deep learning;leadership;machine learning;problem solving;python;r;sql
Senior Data Scientist (Analytics),Grab,Jakarta Metropolitan Area,https://id.linkedin.com/jobs/view/senior-data-scientist-analytics-at-grab-4316462547?position=5&pageNum=2&refId=fA9FObB2cvwGbuRyT9SR8A%3D%3D&trackingId=VqVTz3BRgM1dwV%2Bzmk2yfw%3D%3D,"Company Description About Grab and Our Workplace Grab is Southeast Asia's leading superapp. From getting your favourite meals delivered to helping you manage your finances and getting around town hassle-free, we've got your back with everything. In Grab, purpose gives us joy and habits build excellence, while harnessing the power of Technology and AI to deliver the mission of driving Southeast Asia forward by economically empowering everyone, with heart, hunger, honour, and humility. Job Description Get to Know the Team We drive innovation and operational excellence by turning data into actionable strategies that elevate the end-to-end experience for consumers, driver-partners, and merchant-partners. From optimizing transaction flows and platform efficiency to enhancing reliability, we strive to make Grab the first choice, every time. Get to Know the Role You will be responsible for all matters related to data ETL, creation of dashboards and development of data driven insights. In addition, you will provide day to day data support to the Transformation and Strategy Office team. You will collaborate closely with cross-functional teams including Corporate Strategy, Finance, and Analytics, as well as other key business units. In this role, you are expected to contribute to strategic planning and data-driven insights that support business growth and decision-making. Your work will involve translating analytical findings into actionable recommendations, aligning initiatives across teams, and ensuring strategic priorities are executed effectively to drive organizational impact. You will be directly report to the manager. The role will based onsite. The Critical Tasks You Will Perform Be an industry subject matter expert in using data to measure and analyze business/product performance in each of our markets and lines of business. Lead the exploration of business/product issues/opportunities, uncover insights and/or identify targeted areas for business growth. Localize, tune in-production models to new cities / markets to enable product velocity. Provide thought leadership and generate data-driven hypotheses to solve key Product/Business problems. Develop mixed effect, causal inference models to understand interaction effects or product configurations that are working sub optimally. Build and manage anomaly detection systems to intelligently alert slow-moving changes or sudden anomalies in product or system metrics. Develop analytics tools to help data teams and other disciplines be more at debugging, data summarization and at analysis of results. Qualifications What Essential Skills You Will Need 4+ years of experience, preferably in the e-commerce or the Internet industry. A minimum of Bachelor's/Master's degree, in Analytics, Statistics, Software, Mathematics, Economics, Computer Science or Engineering Experience in foundation in data query/manipulation using SQL and data visualization tools (PowerBI). Strong statistical knowledge - ideally having utilized controlled experiments in the industry. Able to speak and write Both in Bahasa & English Additional Information Life at Grab We care about your well-being at Grab, here are some of the global benefits we offer: We have your back with Term Life Insurance and comprehensive Medical Insurance. With GrabFlex, create a benefits package that suits your needs and aspirations. Celebrate moments that matter in life with loved ones through Parental and Birthday leave, and give back to your communities through Love-all-Serve-all (LASA) volunteering leave We have a confidential Grabber Assistance Programme to guide and uplift you and your loved ones through life's challenges. Balancing personal commitments and life's demands are made easier with our FlexWork arrangements such as differentiated hours What We Stand For At Grab We are committed to building an inclusive and equitable workplace that provides equal opportunity for Grabbers to grow and perform at their best. We consider all candidates fairly and equally regardless of nationality, ethnicity, race, religion, age, gender, family commitments, physical and mental impairments or disabilities, and other attributes that make them unique.",data visualization;etl;leadership;powerbi;sql
Data Scientist Associate - UTPE,PT Astra International Tbk,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/data-scientist-associate-utpe-at-pt-astra-international-tbk-4212980988?position=6&pageNum=2&refId=fA9FObB2cvwGbuRyT9SR8A%3D%3D&trackingId=d%2Bvz7ToN%2FJcon1kG2Nh12A%3D%3D,"Deskripsi Pekerjaan Menentukan data relevan yang bisnis butuhkan serta merancang rekayasa & pengolahan data yang diperlukan Menganalisis dataset untuk menemukan pola dan insight yang relevan dengan pengambilan keputusan bisnis. Persyaratan S1 Statitiska, Teknik Industri IPK >3 Bersedia ditempatkan di mana saja",
Data Scientist - Risk Platform,Cermati.com,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/data-scientist-risk-platform-at-cermati-com-4334237742?position=7&pageNum=2&refId=fA9FObB2cvwGbuRyT9SR8A%3D%3D&trackingId=ff7jljxcdVKhOuH%2BzvbyHg%3D%3D,"Job Description We’re looking for fresh graduates with experience in manipulating datasets and building statistical models for credit risk by leveraging machine learning techniques. You will partner with business, product, and engineering team to explore, determine, analyze, propose, and solve some of the most challenging business problems in lending and reduce risk. You will perform deep-dive exploration and analysis to find improvements in our existing framework. You will be submerged in a fast-paced environment working tightly in a strong team of data scientists and experience firsthand our robust data infrastructure. Responsibilities Perform features selection, parameter binning, and optimize custom predictive machine learning models for credit risk scoring Query, process, cleanse, and verify the integrity of data used for analysis Analyze key metrics to determine risk and explore areas for improvements Create reports and dashboards to monitor model impact and performance Help build the variety of data ingredients needed to do modelling effectively Maintain the credit risk model platform which is utilized by the team Provide advice and guidance on potential efficiency gains and new state-of-the-art credit risk modelling methodologies Qualifications Bachelor degree in an analytical or quantitative discipline (e.g. math, statistics, engineering, computer science), however other disciplines will be considered Experienced in using statistical computer languages such as R, Python SAS, SQL, or advanced MS Excel skills is a plus. Have good communication skills and able to work together in a team Excellent problem-solving skills and have the drive to learn and master new technologies and techniques Willingness to learn new skills independently and have a strong sense of project ownership Not afraid to get your hands dirty to explore data and build statistical models",communication;machine learning;python;r;sql
AI Engineer,Walturn,Indonesia,https://id.linkedin.com/jobs/view/ai-engineer-at-walturn-4341993396?position=8&pageNum=2&refId=fA9FObB2cvwGbuRyT9SR8A%3D%3D&trackingId=%2F4FMrh01X1xDlTnwRGyKYA%3D%3D,"ROLE OVERVIEW We’re looking for an AI Engineer who can architect, implement, and scale autonomous agent systems that turn product ideas into fully-functional mobile apps. You’ll sit at the heart of our R&D efforts combining cutting-edge LLM research with rigorous software engineering to push the boundaries of automated development. KEY RESPONSIBILITIES • Design agent architectures that can plan, reason, and decompose user specs into actionable development tasks. • Prototype and productionize LLM pipelines (e.g., OpenAI, Anthropic, Cohere) leveraging frameworks like LangChain, AutoGen, or custom orchestration layers. • Integrate agents with our cloud backend (Python/FastAPI, PostgreSQL, Redis) and CI/CD pipelines to generate, test, and deploy code autonomously. • Instrument feedback loops & evaluation harnesses to measure tool effectiveness, hallucination rates, and coding accuracy. • Collaborate with front-end and mobile engineers to ensure generated code meets UX, performance, and security standards. • Stay on the bleeding edge of agentic research (ReAct, Reflexion, Chain-of-Thought) and rapidly translate findings into product features. MINIMUM QUALIFICATIONS • 3+ years in back-end or full-stack development with a focus on Python (FastAPI, Django, or Flask). • Proven experience building with LLMs and/or conversational AI (prompt engineering, embeddings, vector DBs like Pinecone/Chroma). • Solid CS fundamentals and OOP expertise; comfortable designing scalable, observable microservices. • Familiarity with cloud infrastructure (AWS, GCP, or Azure) and containerization (Docker, Kubernetes). • Strong analytical mindset and habit of writing thorough unit/integration tests. • Excellent written and verbal communication in English; able to thrive in an async-first environment. PREFERRED QUALIFICATIONS Hands-on work with agent frameworks (LangChain Agents, Microsoft AutoGen, Semantic Kernel, Open-AI function calling, etc.). Graph-based planning or reinforcement learning for tool-use agents. Experience contributing to dev-tooling, compilers, or IDE plugins. Knowledge of mobile app stacks (Flutter, React Native, Swift/Kotlin) and how LLM-generated code integrates with them. Prior startup or high-growth environment experience. WHAT SETS THIS ROLE APART Front-row seat to AI-first product innovation. You’ll turn pure research into a shipping product used by thousands of developers. Autonomy & ownership. You will own large problem spaces end-to-end and have latitude to choose tooling and approaches. High-impact culture. Small team, zero bureaucracy, and a direct line to the founding team.",aws;azure;chroma;ci/cd;communication;containerization;django;docker;fastapi;flask;gcp;kubernetes;llm;microservices;pinecone;postgresql;python;r;react;redis;security
Artificial Intelligence Engineer,BOSNET Distribution Indonesia,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/artificial-intelligence-engineer-at-bosnet-distribution-indonesia-4322553776?position=9&pageNum=2&refId=fA9FObB2cvwGbuRyT9SR8A%3D%3D&trackingId=ovxBrRbGyULMY8uUMtkgBg%3D%3D,"Responsibilities Develop and train machine learning models using Python libraries Perform data preprocessing, cleaning, and analysis to prepare datasets for training. Implement neural networks and time series analyses to solve complex problems. Develop and optimize computer vision algorithms. Collaborate with other team members to integrate AI solutions into business applications. Requirements Bachelor’s degree in Computer Science, Engineering, Mathematics, or related field Strong foundational knowledge in Python Understanding of machine learning and neural networks Experience in creating computer vision and time series analysis is a plus Willing to work WFO from Tebet, Jakarta Selatan",computer vision;data preprocessing;machine learning;neural networks;python;time series
Senior Data Scientist - Credit Scoring,Amar Bank,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/senior-data-scientist-credit-scoring-at-amar-bank-4309677792?position=10&pageNum=2&refId=fA9FObB2cvwGbuRyT9SR8A%3D%3D&trackingId=Lgf3KV94zT6J%2FDLEeAbO2A%3D%3D,"This Senior Data Scientist directly supports Amar Bank’s strategic goals of scaling data-driven lending, improving model governance, and increasing acceptance in new customer segments. Responsibilities Develop, maintain, and improve credit scoring and risk models using Python and SQL Conduct feature engineering and data analysis to improve model performance Collaborate with business, risk management, and IT to ensure models are deployed successfully Document models and processes according to regulatory and internal standards Contribute to process improvements and adoption of new tools (e.g., Vertex AI) Support knowledge transfer across multicultural teams Requirements Proven track record in predictive model development and deployment, ideally in credit risk Strong skills in Python and SQL Understanding of the banking and credit risk domain Experience with cloud platforms (Vertex AI or similar) Strong communication and collaboration skills Ability to work independently and take ownership of projects Fluent English, ability to work in a multicultural environment Bonus Point Experience with regulatory model governance Prior exposure to Asian financial services markets We may use artificial intelligence (AI) tools to support parts of the hiring process, such as reviewing applications, analyzing resumes, or assessing responses. These tools assist our recruitment team but do not replace human judgment. Final hiring decisions are ultimately made by humans. If you would like more information about how your data is processed, please contact us.",communication;data scientist;feature engineering;python;sql;vertex ai
Deep Learning / AI Scientist - Liveness Detection and Biometrics,VIDA Digital Identity,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/deep-learning-ai-scientist-liveness-detection-and-biometrics-at-vida-digital-identity-4212415978?position=1&pageNum=5&refId=vb5ByPxLEAe4OTfzF%2B%2Bfhg%3D%3D&trackingId=6%2FT9xdJQwIXYi2zzFWKQkA%3D%3D,"Our mission is to create innovative, robust, and user-friendly digital identity solutions. We are looking for a passionate and skilled Deep Learning AI Scientist specializing in Liveness Detection and Biometrics to join our dynamic team. Your work will directly impact the security and reliability of VIDA's identity verification systems. Responsibilities: Liveness Detection Development: Design, train, and deploy advanced deep learning models to ensure robust liveness detection, preventing spoofing attacks using photos, videos, masks, or other methods. Design, train and deploy biometric models to correctly identify users Own the full lifecycle of deploying models: from data labelling, working with engineers to design scalable APIs, to monitoring and A/B testing new model versions Stay updated with the latest research in biometrics, computer vision, and deep learning, incorporating new techniques to improve VIDA’s products Collaborate with business, product, operations and engineering teams to deliver impact for our customers Work independently or in a team to solve complex problem statements Requirements: An advanced degree in a quantitative field, and 3+ years of hands-on experience in deep learning model development for biometrics or liveness detection or a similar field. Deep understanding of modern computer vision techniques, deep learning and machine learning Experience developing and deploying machine learning models in production Experience with adversarial training to enhance model robustness Proficient in Python, C++, Scala, or Java Familiarity with modern deep learning frameworks such as TensorFlow, PyTorch, MXNet Familiarity with cloud platforms like AWS, GCP, or Azure for model deployment. Experience in on-device inference for machine learning models is a plus Take pride in taking ownership and driving projects to have business impact Thrive in a fast moving collaborative environment What are we trying to solve? We have 7.5 billion people on Earth, of which over 1 billion cannot securely prove their identity right now. Every year, 140 million babies are born, of which 40 million go unregistered. Simply put, these people are deprived of social benefits, such as education and health, their civil rights to vote and travel; and are excluded from the economy because they cannot sign up for bank accounts, loans, welfare programs etc. We believe this is unacceptable, and needs to change. At VIDA , We are creating a frictionless digital identity system. One that fulfills the needs and expectations of our times, and is available anywhere, for everyone. Why are we solving this problem? The United Nations (UN) and World Bank ID4D initiatives aim to provide everyone on the planet with a legal identity by 2030. This deadline is just 9 years away, we are expecting a digital identity to be a legal human right by then and we at VIDA want to be pioneers in leading this change. Who are we? We are a highly driven bunch of people to solve this problem for our own reasons. Whether it is to solve for misleading doctors, or because we didn’t get access to fair ration due to corruption - Our collective goal aligns.",aws;azure;c;computer vision;deep learning;gcp;java;machine learning;model deployment;monitoring;python;pytorch;scala;security;tensorflow;testing
Data Scientist,PT. CYBERTREND INTRABUANA,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/data-scientist-at-pt-cybertrend-intrabuana-4317436414?position=2&pageNum=5&refId=vb5ByPxLEAe4OTfzF%2B%2Bfhg%3D%3D&trackingId=0f62SS4%2BcocvOCImISHZ6Q%3D%3D,"About The Role We are SmartCyber, member of Cybertrend, one of the leader data science consultants in Indonesia. At CYBERTREND, Delivery Department is one of our core capabilities in realizing solutions for clients. As DATA SCIENTIST , you will be part of the core team, in ensuring that our product and solution delivered to customers are designed and developed with highly scalable, reliable and maintainable system. Along with owning the entire life cycle of all CYBERTREND’s projects, analyse data from multiple angles, looking for trends that highlight problems or opportunities. We Are Looking Someone With A Bachelor’s Degree in Software Engineering, Computer Science, Information Systems, Mathematics, Statistics, or a similar field At least 5 years of experience as a Data Scientist/ Machine Learning Engineer, with solid understanding of Data Science and Machine Learning fundamentals and experience taking Data Science models into production Experience using Data Science technology, framework, tools and Algorithm (e.g., Machine learning / phyton / R / Data Mining / Statistics / K-NN / Naïve Bayes / SVM / Weka / SPSS / Sentiment Analysis / NLP) Proven experience in understanding Business needs and formulating Data Science solutions to solve the issues High-level experience in Data Mining High-level experience in one or more natural language processing topics: tagging, syntactic parsing word sense disambiguation, topic modelling; contextual text mining and application of deep learning to NLP High-level experience working with a wide range of predictive and decision models and data mining technique, as well as tools for developing such models Ability to communicate with business user to capture business data needs Strong analytical thinking and problem solving High-level written and verbal communication skills The Work You’ll Do As part of cross-functional and work together with Sales, Presales and Product team to design and build end-to-end Data Science solutions Work closely with business to identify issues and use data to propose solutions for effective decision making Build algorithms and design experiments to merge, manage, interrogate and extract data to supply tailored reports to colleagues, customers or the wider organization Use machine learning tools and statistical techniques to produce solutions to problems Test data mining models to select the most appropriate ones for use on a project Horizon scan to stay up to date with the latest technology, techniques and methods Conduct research from which you’ll develop prototypes and proof of concepts Create Technical Proposal for Project Conduct knowledge acceleration to internal team What Cybertrend Can Offer You The unique opportunity to work within data science and artificial intelligence solution for various industries – real world data science, AI , Data Management and Governance experiences Investment in your personal growth and skill development (clear career paths, mentorship and coaching, learning development, etc) Attractive compensation and benefits packages An open-minded culture with innovative, autonomous teams A clear set of company core values that guide everything we do: GROWTH mindset, SOLUTION oriented, INNOVATIVE achiever, COMPASSIONATE, GOTONG ROYONG and Cool & FUN",communication;data scientist;deep learning;machine learning;natural language processing;nlp;problem solving;r;sentiment analysis;svm
Principal Data Scientist (Indonesia),Thakral One,"Jakarta, Indonesia",https://id.linkedin.com/jobs/view/principal-data-scientist-indonesia-at-thakral-one-4313743010?position=3&pageNum=5&refId=vb5ByPxLEAe4OTfzF%2B%2Bfhg%3D%3D&trackingId=3eIKoyZSBteQeTsst6MWGw%3D%3D,"The Opportunity. We are seeking an experienced Principal Data Scientist to support data-driven initiatives for one of our global clients in the payments and financial services domain. The role will be part of a regional analytics and consulting team, responsible for delivering high-impact analytical solutions that enable business growth, enhance customer engagement, and optimize portfolio performance. This is an individual contributor role focused on executing complex data science projects and generating actionable insights that drive strategic decision-making. The position requires strong technical expertise, business acumen, and the ability to translate data into measurable business outcomes. The Role. Execute and deliver end-to-end data science and analytics projects that address key business priorities in areas such as portfolio management, customer segmentation, acquisition, digital adoption, and risk optimization. Translate business challenges into analytical frameworks and apply appropriate statistical or machine learning techniques to generate insights and recommendations. Build, test, and deploy predictive and prescriptive models using advanced data science methods and tools. Work with large and complex data sets across multiple environments (on-premise and cloud-based). Collaborate with internal consulting and business stakeholders to define scope, design solutions, and communicate outcomes effectively. Deliver findings and recommendations through clear, data-driven storytelling and visualization. Ensure project quality, consistency, and adherence to data science standards and best practices. Proactively identify opportunities to apply analytics and data science to solve emerging business challenges. The Expertise. Bachelor’s or Master’s degree in a Quantitative discipline (Statistics, Mathematics, Computer Science, Engineering, Economics, etc.) At least 8 years of professional experience in data science, analytics, or statistical modeling with banking, payments, or financial services sectors. Strong proficiency in Python, R, and SQL , with experience in big data platforms (Hadoop, Spark, Hive) and cloud environments (GCP, AWS, Azure). Solid understanding of statistical and machine learning methods , such as regression, classification, clustering, gradient boosting, and neural networks. Experience with data visualization tools (Tableau, Power BI, or similar). Proven ability to manage multiple concurrent analytics projects with diverse stakeholders. Excellent communication and presentation skills, with the ability to convey complex analytical concepts to non-technical audiences. Strong analytical mindset, problem-solving ability, and attention to detail. Other Relevant Information: Location: Jakarta, Indonesia Contract-Based (1 year) Full Onsite About us. Thakral One is a consulting and technology services company headquartered in Singapore, with a pan-Asian presence. We focus primarily around technology-driven consulting, adoption of value-added bespoke solutions, enabling enhanced decision support through data analytics, and embracing possibilities in the cloud. We are heavily inclined towards building capabilities collaboratively with clients and believe strongly in improving grounded and practical outcomes. This approach is possible through our partnership with leading global technology providers and internal R&D teams. Our clients come from Financial Services, Banking, Telco, Government, Healthcare, and Consumer-oriented organisations.",aws;azure;clustering;communication;customer segmentation;data scientist;data visualization;gcp;gradient boosting;hadoop;machine learning;neural networks;presentation skills;python;r;segmentation;spark;sql;tableau
Senior Data Scientist (Analytics) - Transaction Platform,Grab,Jakarta Metropolitan Area,https://id.linkedin.com/jobs/view/senior-data-scientist-analytics-transaction-platform-at-grab-4321718413?position=4&pageNum=5&refId=vb5ByPxLEAe4OTfzF%2B%2Bfhg%3D%3D&trackingId=66CcLG93HqU8UH0WPTXyfg%3D%3D,"Company Description About Grab and Our Workplace Grab is Southeast Asia's leading superapp. From getting your favourite meals delivered to helping you manage your finances and getting around town hassle-free, we've got your back with everything. In Grab, purpose gives us joy and habits build excellence, while harnessing the power of Technology and AI to deliver the mission of driving Southeast Asia forward by economically empowering everyone, with heart, hunger, honour, and humility. Job Description Get to Know the Team We drive innovation and operational excellence by turning data into actionable strategies that elevate the end-to-end experience for consumers, driver-partners, and merchant-partners. From optimizing transaction flows and platform efficiency to enhancing reliability, we strive to make Grab the first choice, every time. Get to Know the Role You will report to the Product Analytics Manager, TP and you'll have the unique opportunity to collaborate across disciplines (Product, Business, Engineering, Design, Data Science) to transform data into dynamic solutions. Your insights will directly contribute to developing groundbreaking products and initiatives, setting new benchmarks for excellence. This isn't just any role; it's a chance to make a tangible impact on millions of lives every day. You will report to Analytics Manager and based in Jakarta office. The Critical Tasks You Will Perform You will understand our requirements and outcomes to ensure data-driven decision-making. You will conduct tailored analyses for specific products and operations, define critical business metrics, track them rigorously, and recommend continuous improvements. You will frame business scenarios and propose features that impact critical business processes and decisions. You will transform requirements into concise insights through reports, presentations, and dashboards, and consolidate data from multiple sources to create comprehensive views for decision-making. You will develop data pipelines and custom data science models to solve identified problems. You will launch A/B tests, analyze the results, and provide recommendations based on your findings. Qualifications What Essential Skills You Will Need You have at least 4 years of experience in data-related or quantitative fields such as Analytics, Science, Statistics, or Mathematics. You are fluent with SQL, Python, R or other scripting/programming languages. You are experienced in handling large datasets and maintaining complex Extract, Transform and Load (ETL) processes. You have solid statistical knowledge and hands-on experience running and analysing controlled experiments. You are proficient in creating dashboards using Tableau, PowerBI or other visualisation tools. Additional Information Life at Grab We care about your well-being at Grab, here are some of the global benefits we offer: We have your back with Term Life Insurance and comprehensive Medical Insurance. With GrabFlex, create a benefits package that suits your needs and aspirations. Celebrate moments that matter in life with loved ones through Parental and Birthday leave, and give back to your communities through Love-all-Serve-all (LASA) volunteering leave We have a confidential Grabber Assistance Programme to guide and uplift you and your loved ones through life's challenges. Balancing personal commitments and life's demands are made easier with our FlexWork arrangements such as differentiated hours What We Stand For At Grab We are committed to building an inclusive and equitable workplace that provides equal opportunity for Grabbers to grow and perform at their best. We consider all candidates fairly and equally regardless of nationality, ethnicity, race, religion, age, gender, family commitments, physical and mental impairments or disabilities, and other attributes that make them unique.",etl;powerbi;product analytics;python;r;sql;tableau
Machine Learning Engineer (LLM),BJAK,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/machine-learning-engineer-llm-at-bjak-4337777155?position=5&pageNum=5&refId=vb5ByPxLEAe4OTfzF%2B%2Bfhg%3D%3D&trackingId=yMNHTLpsqV9Atzk9zXE5gw%3D%3D,"Transform Language Models into Real-World Applications We’re building AI systems for a global audience. We are living in an era of AI transition - this new project team will be focusing on building applications to enable more real world impact and highest usage for the world. This is a remote role based in Indonesia, working closely with our HQ in Malaysia and cross-functional regional teams. You’ll operate across the stack, from backend logic and integration to frontend delivery, building intelligent systems that scale fast and matter deeply. Why This Role Matters You’ll fine-tune state-of-the-art models, design evaluation frameworks, and bring AI features into production. Your work ensures our models are not only intelligent, but also safe, trustworthy, and impactful at scale. What You’ll Do Fine-tune & adapt - Use LoRA/QLoRA to optimize open-source models (LLaMA, Mistral, Gemma) Engineer prompts & curates data - Craft prompts and datasets that reflect tone, brand voice, and safety. Evaluate models – Build metrics pipelines for perplexity, toxicity, and relevance to ensure safe and high-quality outputs. Deploy & monitor – Scale models into production with performance optimization and monitoring for drift. Collaborate & deliver – Partner with product, engineering, and design teams to launch user-facing AI features. What Is It Like Likes ownership and independence Believe clarity comes from action - prototype, test, and iterate without waiting for perfect plans. Stay calm and effective in startup chaos - shifting priorities and building from zero doesn’t faze you. Bias for speed - you believe it’s better to deliver something valuable now than a perfect version much later. See feedback and failure as part of growth - you’re here to level up. Possess humility, hunger, and hustle, and lift others up as you go. Requirements Strong experience in transformers, deep learning, and fine-tuning methods (LoRA/QLoRA, SFT, distillation). Proficiency with PyTorch (preferred) or TensorFlow. Skilled in prompt engineering and dataset curation for alignment with tone, safety, and trust. Familiar with evaluation metrics: perplexity, toxicity, relevance. Strong software engineering foundations in algorithms, data structures, and clean code practices. Nice to Have Prior work in text generation, moderation, or personalization. Experience with RLHF or reinforcement learning in LLMs. Contributions to open-source ML projects. What You’ll Get Flat structure & real ownership Full involvement in direction and consensus decision making Flexibility in work arrangement High-impact role with visibility across product, data, and engineering Top-of-market compensation and performance-based bonuses Global exposure to product development Lots of perks - housing rental subsidies, a quality company cafeteria, and overtime meals Health, dental & vision insurance Global travel insurance (for you & your dependents) Unlimited, flexible time off Our Team & Culture We’re a densed, high-performance team focused on high quality work and global impact. We behave like owners. We value speed, clarity, and relentless ownership. If you’re hungry to grow and care deeply about excellence, join us. About Bjak BJAK is Southeast Asia’s #1 insurance aggregator with 8M+ users, fully owned by its employees. Headquartered in Malaysia and operating in Thailand, Taiwan, and Japan, we help millions of users access transparent and affordable financial protection through Bjak.com. We simplify complex financial products through cutting-edge technologies, including APIs, automation, and AI, to build the next generation of intelligent financial systems. If you're excited to build real-world AI systems and grow fast in a high-impact environment, we’d love to hear from you.",deep learning;monitoring;pytorch;tensorflow;text generation
Data Scientist,Philip Morris International,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/data-scientist-at-philip-morris-international-4278782491?position=6&pageNum=5&refId=vb5ByPxLEAe4OTfzF%2B%2Bfhg%3D%3D&trackingId=S7qdEup%2FSHhoN1RoXlM%2FNQ%3D%3D,"MAKE HISTORY WITH US! At PMI, we’ve chosen to do something incredible. We’re totally transforming our business, and building our future on smoke-free products with the power to improve the lives of a billion smokers worldwide. With huge change, comes huge opportunity. So, wherever you join us, you’ll enjoy the freedom to dream up and deliver better, brighter solutions and the space to move your career forward in endlessly different directions. Role Overview You are highly driven to constantly innovate and drive positive change, but more importantly, you consistently deliver great results. As a data engineer in PMI Business Solutions, you will have the opportunity to be a part of something different. This position offers exceptional opportunities for every candidate to grow their technical and non-technical skills. If you are selected, you have the opportunity to really make a difference to our business by inventing, enhancing and building new system, delivering results, working on exciting and challenging projects. To find out more about eligibility to apply for internal jobs, please refer to the Open Sourcing Employee Guidebook on the Internal Careers Portal. Your ‘day to day’ Creating, Testing and Deploying Pipelines: Design, develop, and maintain data pipelines for efficient data ingestion, processing, and delivery. Ensure Data Completeness and Quality: Implement mechanisms to ensure data completeness, accuracy, and consistency across all data sources and processes. Optimizing and Maintaining Warehouse: Continuously improve the performance and scalability of the data warehouse, implementing optimization techniques and best practices. Continuous Improvement: Identify opportunities for process optimization and automation, striving for continuous improvement in data management practices. Data Analysis: Analyze and interpret data to provide actionable insights and recommendations to stakeholders, supporting data-driven decision-making processes. Work with Vendors: Collaborate with external vendors to integrate new data sources into the data ecosystem, ensuring seamless data flow and integration. Problem-Solving: Leveraging innovative approaches to optimize processes and enhance data quality. Proactive Role: Actively anticipate and resolve potential data issues before they escalate, demonstrating a proactive approach to data. Who we’re looking for You have graduated in (Business) Informatics, IT, computer science or a related field. 5 + years of experience working with SQL Server such as Snowflake, S3 buckets, CI/CD pipelines, Jenkins or GIT. Proficient in SQL and an additional programming language such as PowerShell or Python. Hands-on experience with cloud platforms such as AWS, Azure, or Google Cloud Platform (GCP). Ideal candidates will have a deep understanding of technical and functional designs for Databases, Data Warehousing, ETL, Reporting, and Data Mining areas. Strong understanding of data modeling concepts and techniques, including dimensional modeling and schema design, to ensure efficient data storage and retrieva Preferred Qualification Knowledge of software engineering best practices across the development lifecycle, including agile methodologies, coding standards, code reviews, source management, build processes, testing, and operations. Implement standardized, automated operational processes to deliver accurate and timely data for reporting to meet or exceed SLAs. Understanding of development and management of data infrastructure and service. Proven success in communicating with users, other technical teams, and senior management to collect requirements, describe data modeling decisions and data engineering strategy. Experience working directly with remote technical teams Please note that only online applications will be taken into consideration. Only selected candidates will be contacted. 10787",agile;aws;azure;ci/cd;data engineering;data ingestion;data modeling;data warehouse;dimensional modeling;etl;gcp;git;google cloud;jenkins;powershell;python;s3;scalability;snowflake;sql;testing
Quality Assurance Engineer (Banking),PT. Adi Data Informatika,"Jakarta, Indonesia",https://id.linkedin.com/jobs/view/quality-assurance-engineer-banking-at-pt-adi-data-informatika-4323153601?position=7&pageNum=5&refId=vb5ByPxLEAe4OTfzF%2B%2Bfhg%3D%3D&trackingId=oG9pz%2BS60%2BzNtdFUN8M9Ag%3D%3D,"Quality Assurance & Testing (Banking) Menyusun test plan, test scenario, dan test case sesuai kebutuhan bisnis perbankan. Melakukan Functional Testing , Integration Testing , System Testing , Regression Testing , hingga User Acceptance Testing (UAT) . Melakukan API testing dan database validation untuk memastikan integritas data transaksi. Menguji aplikasi mobile dan web banking (mobile banking, internet banking, internal banking apps).",integration testing;testing
Senior Data Scientist,PT Bank Digital BCA (BCA Digital),"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/senior-data-scientist-at-pt-bank-digital-bca-bca-digital-4324262037?position=8&pageNum=5&refId=vb5ByPxLEAe4OTfzF%2B%2Bfhg%3D%3D&trackingId=rOwhOzAqxd7Qgv7wKxrhIw%3D%3D,"Responsibilities Key Responsibilities: Drive leadership in Data Science team in developing and deploy predictive models for customer segmentation, churn prediction, and personalization services. Experiences in Big Data technologies to improve scalability, real-time analytics, and data-driven decision-making. Explore and implement AI technologies including Gen AI, LLM, and other advanced AI applications to improve Our operational processes and enhance customer experience. Design and implement ML algorithms and Auto-ML for recommendation systems, personalized marketing, and other use cases. Collaborate with Data Engineering to ensure scalable data pipelines, robust data architecture, and efficient data lake/warehouse solutions. Perform exploratory data analysis and generate actionable insights for business stakeholders. Lead initiatives on advanced analytics, including NLP, conversational AI, and intelligent automation. Ensure compliance with data governance, security, and regulatory requirements. Able to review model flow, data flow and architecture, and understand the impact of changes to data technology that will be implemented. Mentor junior data scientists and contribute to building best practices in model development and deployment. Partner with IT and business teams to integrate models into production systems and monitor performance. Requirements Job Requirements Bachelor’s or Master’s degree in Data Science, Computer Science, Statistics, Mathematics, or related field. Minimum 7+ years of experience in data science roles, preferably in banking, fintech, or digital platforms. Proven track record of delivering machine learning and AI models in production environments. Strong proficiency in Python or R, and experience with ML frameworks (TensorFlow, PyTorch, Scikit-learn). Hands-on experience with Gen AI, LLMs, and related frameworks (e.g., Hugging Face, LangChain). Expertise in Big Data technologies such as Apache Spark, Hadoop, Kafka, and distributed computing. Strong SQL skills and familiarity with data lake/warehouse architectures. Experience with cloud platforms and containerization. Solid understanding of data modeling, feature engineering, and model evaluation techniques. Knowledge of MLOps practices and tools for CI/CD in ML workflows. Familiarity with digital banking products, customer lifecycle, and risk management. Understanding of regulatory compliance in Indonesian banking. Ability to lead projects and mentor team members.",apache;ci/cd;containerization;customer segmentation;data engineering;data modeling;feature engineering;hadoop;kafka;leadership;llm;machine learning;mlops;model evaluation;nlp;python;pytorch;r;scalability;scikit-learn;security;segmentation;spark;sql;tensorflow
Artificial Intelligence & Machine Learning Lead,PT Link Net Tbk,"Tangerang, Banten, Indonesia",https://id.linkedin.com/jobs/view/artificial-intelligence-machine-learning-lead-at-pt-link-net-tbk-4305223020?position=9&pageNum=5&refId=vb5ByPxLEAe4OTfzF%2B%2Bfhg%3D%3D&trackingId=lkiLVVS22E5paapRwULRGA%3D%3D,"Develop and implement AI and predictive modeling solutions (e.g., B2S Funnel Modelling, OA Penetration, Customer Behavior Models) to drive future growth and improve forecast accuracy Oversee MLOps practices to ensure scalable, reliable, and sustainable deployment of AI/ML models for operational improvement Transform large and complex datasets into actionable business intelligence that optimizes operational costs, customer engagement, and growth opportunities Drive continuous improvement of predictive analytics to enhance forecast accuracy and business planning efficiency Align AI strategy with business priorities by engaging cross-functional teams to integrate predictive models into decision-making processes Facilitate capability building for stakeholders to effectively adopt and utilize AI-driven insights Requirements Bachelor's degree in Data Science, Statistics, Computer Science, Business Analytics, or related field 5+ years in data science, AI/ML, or advanced analytics, Proven track record in leading AI/ML projects from ideation to deployment at scale Exposure to MLOps implementation, predictive modeling, and data-driven business transformation Advanced expertise in machine learning, deep learning, and AI frameworks (e.g., TensorFlow, PyTorch, Scikit-learn) Strong background in predictive analytics, natural language processing (NLP), and data engineering concepts Proficiency in programming languages (Python, R, SQL) and cloud platforms (AWS, GCP, Azure) Familiarity with MLOps pipelines and model lifecycle management Understanding of business process automation and AI-driven decision systems Willing to work in: Karawaci, Tangerang Benefits Medical insurance Medical checkup",aws;azure;business analytics;business intelligence;data engineering;deep learning;gcp;machine learning;mlops;natural language processing;nlp;python;pytorch;r;scikit-learn;sql;tensorflow
"TikTok Shop by Tokopedia - Data Analyst Specialist, Semi-Consignment - Indonesia",TikTok,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/tiktok-shop-by-tokopedia-data-analyst-specialist-semi-consignment-indonesia-at-tiktok-4320523837?position=10&pageNum=5&refId=vb5ByPxLEAe4OTfzF%2B%2Bfhg%3D%3D&trackingId=CM79Qz0SX%2FmQetnWB2oXWg%3D%3D,"Responsibilities About the team We are the Indonesia TikTok Shop Semi-Consignment team, committed to helping small and medium-sized sellers without extensive e-commerce operation capabilities better succeed on TikTok Shop through operational actions such as managing subsidies, creator matchmaking, and ads. Roles & Responsibilities: 1. Based on business strategy, in response to business operation strategies and phased business objectives, be responsible for special project analysis work. By mining features in areas such as user behavior preferences, product competitiveness, content creator ecosystem, and industry trends from massive e-commerce business data, identify potential business problems or opportunities, output professional analysis reports, provide data science support and business insights for strategy implementation, and support the formulation and decision-making of business strategies; 2. Based on an understanding of business models and operating strategies, responsible for designing and building the core daily, weekly, and monthly business operating metric systems and monitoring products, collaborating with cross functions to promote the implementation of data products, and providing productized and systematic solutions for daily business operations and analysis; 3. Responsible for clarifying the definitions and calculation logic of key metrics, formulating data standards and specifications, and improving the efficiency of team data analysis and data quality; 4. Responsible for the design and management of AB tests, ensuring that the experimental design is scientifically sound and reasonable, meets business objectives and statistical significance requirements, promotes the implementation of AB test results, and outputs experimental conclusion reports; 5. Responsible for tasks such as data preparation and feature engineering, providing a quantitative basis for the platform's business decisions, and driving the achievement of the platform's business goals. Qualifications Minimum Qualifications: - Bachelor's degree or above, with major in statistics, mathematics, computer science and technology, data science, economics, finance, marketing, and other related fields. - 3 years minimum of work experience related to data analysis in e-commerce platforms or the industry, with preference given to those with special project experience in data science or business analysis. - High-level fluency in English for listening, speaking, reading, and writing to be used as the primary language to communicate with the internal team, cross functions, and stakeholders from different countries. Preferred Qualifications: - Familiarity with e-commerce business logic (such as user operation, product operation, marketing activities, supply chain management, etc.) will be a plus. About TikTok TikTok is the leading destination for short-form mobile video. At TikTok, our mission is to inspire creativity and bring joy. TikTok's global headquarters are in Los Angeles and Singapore, and we also have offices in New York City, London, Dublin, Paris, Berlin, Dubai, Jakarta, Seoul, and Tokyo.​ Why Join Us Inspiring creativity is at the core of TikTok's mission. Our innovative product is built to help people authentically express themselves, discover and connect – and our global, diverse teams make that possible. Together, we create value for our communities, inspire creativity and bring joy - a mission we work towards every day.​ We strive to do great things with great people. We lead with curiosity, humility, and a desire to make impact in a rapidly growing tech company. Every challenge is an opportunity to learn and innovate as one team. We're resilient and embrace challenges as they come. By constantly iterating and fostering an ""Always Day 1"" mindset, we achieve meaningful breakthroughs for ourselves, our company, and our users. When we create and grow together, the possibilities are limitless. Join us.​ ​ Diversity & Inclusion​ TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.​",feature engineering;monitoring
AI Agent Development Contractor (Project-Based),modernvet,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/ai-agent-development-contractor-project-based-at-modernvet-4336809362?position=1&pageNum=7&refId=coILZsHqzI7d%2FJg4ErNnSw%3D%3D&trackingId=60nznN4b9ewGn6xf9jvAnA%3D%3D,"Location: Jakarta / Hybrid Engangement: I nitial 3-month project (extendable) Why this role exists Modernvet built Artemis to deliver instant, reliable answers to customers 24/7, while handing off critical or time-sensitive cases to human agents. Weʼre hiring a project-based contractor to accelerate Artemisʼ capabilities, expand coverage, and measurably improve customer experience. Primary Outcome / KPI Automated Resolution Rate: Achieve and sustain  60% month-over-month (per Intercom resolution metric) Maintain or improve CX Score while scaling automation What youʼll own Task creation & refinement (end-to-end) Build, improve, and QA multi-turn tasks (guided flows) including but not limited to: Booking / Rescheduling / Cancelling appointments Sign up / Forgot password flows Tele consultation: recommend when appropriate, check tickets, guide booking Points: look up points balance, explain usage Pet clinical history lookup: Look up pet information and history Account billing history: Look up historical transaction history, medicine prescription, etc Ensure that existing tasks and cleaned up and refactored when necessary to ensure context-based probing and agent hand off Refill prescription Home visit Imaging/lab test results Urgent/emergency cases Marketing campaigns Payment confirmations Knowledge gap management Use Intercomʼs gap tools to identify unmet intents/FAQs Verify with CS/Ops before adding content Close knowledge gaps with additional articles and internal documentation Automated outbound messaging Utilize Intercoms outbound workflow management to create flows that automate our outbound messaging needs. This includes but is not limited to: Appointment reminders Appointment confirmation Vaccination reminders Information architecture & accuracy Keep Artemisʼ static information (Q&A) fully up to date with Ops (e.g., pricing, terms & conditions, clinic hours, holidays) Build a clean content hierarchy: folders, naming conventions, tags Document app features & flows with screenshots; explain points usage clearly Reporting & insight (in Intercom) Build dashboards in Intercom to monitor: resolution rate, involvement/deflection, CX score, handoff rate, top intents, fail reasons, knowledge gap burn-down, and task completion Keep dashboards current; share weekly insights & next actions Thorough testing & QA (critical) Design and run test plans for each task/knowledge addition: Happy paths, alternate paths, edge cases, ambiguous inputs, language variants (ID/EN), date/time constraints, policy/eligibility checks Regression tests after changes; capture examples; propose fixes Define pass/fail criteria and sign-off checklists Partner with Engineering on data connectors/APIs Draft and communicate requirements for the endpoints Artemis needs (fields, validation, expected responses, error states) Coordinate with engineers on delivery, review responses against requirements, and run UAT in Artemis before go-live You donʼt need to implement APIs—clear specs & coordination are the goal Operational alignment & hygiene Sync with Clinic Ops on updates (services, availability rules) Maintain a tidy content repo (folders, owners, updated dates) Keep a visible backlog/changelog in Notion Requirements 2+ years as CX operations lead or engineering background with experience working with customer service Experience designing multi-turn flows with variables, conditions, validations, and graceful handoffs Strong logical thinking, troubleshooting, and attention to detail; comfortable defining edge cases Data-literate: build dashboards, interpret trends, and turn insights into changes Excellent communication in Bahasa Indonesia & English Work well cross-functionally, primarily with CS ops teams to understand SOPʼs and guidelines and medical team to understand Nice to have Healthcare/veterinary or scheduling domain familiarity Working knowledge of payload shapes/JSON when drafting endpoint requirements Tools: Intercom (Workflows/Fin/Articles/Insights), Notion, Slack, Amplitude/Segment Powered by JazzHR GM8oRZNxEy",communication;testing
Data Scientist Manager - Zurich Asuransi Indonesia,Zurich Insurance,Jakarta Metropolitan Area,https://id.linkedin.com/jobs/view/data-scientist-manager-zurich-asuransi-indonesia-at-zurich-insurance-4303884674?position=2&pageNum=7&refId=coILZsHqzI7d%2FJg4ErNnSw%3D%3D&trackingId=c5bP1ZgnAG%2FLp9hed0cJTQ%3D%3D,"Job Summary Lead the development and implementation of machine learning models and data science solutions. They work closely with business stakeholders to identify opportunities for data-driven insights, and they are responsible for developing and implementing cutting-edge algorithms, models, and analytical solutions. Job Qualifications Background education in Data Science, Statistics, Computer Science, Actuarial Science, or related field. 5-7+ years of experience in data science, with at least 2 years in a leadership role. Prior experience in insurance or financial services is highly preferred. Proficiency in Python, R, SQL, and machine learning frameworks (e.g., Scikit-learn, TensorFlow). Strong understanding of statistical modeling, predictive analytics, and data visualization tools (e.g., Power BI, Tableau). Experience with big data platforms (e.g., Hadoop, Spark) and cloud environments (AWS, Azure, GCP) Excellent communication and storytelling skills to translate complex data into actionable insights. Key Accountabilities Collaborate with cross-functional teams to identify business requirements, design experiments, collect and analyze data, and build predictive models. Have expertise that will contribute to enhancing data-driven decision-making processes and improving business outcomes. Cleaning, processing, and analyzing data to prepare it for use in machine learning models. Developing, testing, and validating machine learning models using appropriate toolsDeploying models into production systems and monitoring their performance. Collaborating with the Data Science & Data Engineering team in developing machine learning models and data science solutions. Collaborating with business stakeholders to identify opportunities for data-driven insights. Defining project objectives and timelines, and managing project execution. Contributing to the development of new data science and machine learning solutions. Communicating results and insights to stakeholders through presentations and reports. Staying up-to-date with industry trends and emerging technologies in data science and machine learning. Performance Management Accountabilities Demonstrate commitment to corporate values. Take accountability for participating in the performance management cycle. Take action to improve performance on the job. Assist and support co-workers. Take action to manage own personal development. You are the heart & soul of Zurich! At Zurich, we like to think outside the box and challenge the status quo. We take an optimistic approach by focusing on the positives and constantly asking What can go right? We highly value the experience and know-how of our employees and offer a wide range of opportunities across business areas to encourage you to apply for new opportunities within Zurich when you are ready for your next career step. Let’s continue to grow together! Location(s): ID - Head Office - MT Haryono Remote working: Schedule: Full Time Recruiter name: Ayu Candra Sekar Rurisa Closing date:",aws;azure;communication;data engineering;data visualization;gcp;hadoop;leadership;machine learning;monitoring;python;r;scikit-learn;spark;sql;tableau;tensorflow;testing
Solution Engineer,H3C,"Jakarta, Indonesia",https://id.linkedin.com/jobs/view/solution-engineer-at-h3c-4323587126?position=3&pageNum=7&refId=coILZsHqzI7d%2FJg4ErNnSw%3D%3D&trackingId=PgajQQd1dHnI3akgC7o%2Bzg%3D%3D,"About H3C: H3C is an industry leader in the provision of Digital Solutions and is committed to becoming the most trusted partner of its customers in their quest for business innovation and digital transformation. We offer a full portfolio of Digital Infrastructure products, spanning across compute, storage, networking, 5G, security and related domains, and provide a comprehensive one-stop digital platform that includes cloud computing, big data, artificial intelligence (AI), industrial internet, information security, intelligent connectivity, AI vision, and edge computing, as well as end-to-end technical services. We are also the exclusive provider of HPE® servers, storage and associated technical services in China. ""Shaping the Digital Future for a Better Life” is the corporate vision of H3C. We are aiming to drive the development of the digital economy, and together with customers and partners, to create a better life for all to enjoy. Purpose of the Role : As a Solution Engineer (Presales) , you will be responsible for interacting and to determine prospective clients’ needs and explain the value of our product’s technological capabilities and business value with the client. The ideal candidate should be able to clearly articulate highly technical concepts to all prospective clients. Responsibilities:- Clearly articulate technical capabilities and give technical demonstrations. Partner with the sales team to generate leads, follow-up all projects related technical matters. Prepare presentation for Projects, Proposals and Bill Of Materials (BOM). Prepare of PoC documents to guide customer requirements. Prepare of SoC for customer reference of tender bidding. Support the constant communication with prospective clients. Provide general technical support to partners and clients. Involve in project implementation and roll-out process. As a technology Prime of a specific technology of solution from the company. Qualifications:- Minimum a Bachelor Degree in any related field. Ability to discuss highly technical concepts with prospective leads. Strong verbal, written, and interpersonal skills, and excellent in presentation skill. At least 3 years’ experience in working as a Solution Engineer or Presales or related technical role. Familiar of part of the Internet Services Providers (ISP) technology listed with evidence, Campus Network, Data Center Network, WAN, WiFi, HCI, Server and Storage, Cloud, Security or 5G. Chinese language skill will be an added advantage as require to communicate with Chinese speaking customers and HQ. Willingness to travel.",cloud computing;communication;networking;security
AI Developer (Remote),BJAK,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/ai-developer-remote-at-bjak-4337975880?position=4&pageNum=7&refId=coILZsHqzI7d%2FJg4ErNnSw%3D%3D&trackingId=1hxhKZQJc14TDcZZV%2F3gMQ%3D%3D,"Shape AI That Powers the Future of Financial Access Across Southeast Asia At BJAK, we’re using AI to solve meaningful problems - from fraud detection and risk modeling to personalized experiences that make insurance and financial services more inclusive. We’re looking for a AI Engineer based in Indonesia to play a key role in building and scaling these systems. This role combines senior-level engineering depth with team leadership, reporting directly to our Head of AI. You’ll be both an individual contributor and a technical mentor, working hands-on with models while also guiding junior engineers and contributing to the team's growth. Why This Role Matters You’ll build core AI systems that serve millions of users across the region. You’ll act as the right hand to the Head of AI, shaping direction, execution, and standards. You’ll help build a lean, high-performance AI team by interviewing, mentoring, and coaching. You’ll set the technical bar, leading by example in code quality, delivery, and problem-solving What You’ll Do Design and deploy production-grade machine learning models for business-critical use cases. Collaborate closely with engineering, data, and product teams to identify and deliver AI solution.s Lead technical decisions on model architecture, system design, and deployment pipelines. Own end-to-end model lifecycle: from data preparation to training, validation, monitoring, and retraining Act as a mentor to junior AI engineers - reviewing code, guiding projects, and supporting growth Support hiring: interview candidates, evaluate technical fit, and contribute to building a world-class team Champion AI best practices, experimentation, and continuous improvement Stay current with AI advancements and evaluate what’s worth bringing into our stack You’ll Thrive Here If You... Are both a builder and a leader - you roll up your sleeves and raise the bar for others Get excited about shipping AI systems that work in the real world Enjoy helping teammates grow and succeed - and do it without ego Can bring clarity and structure to ambiguity Thrive in a high-ownership, fast-paced startup culture Care about impact - not just model accuracy, but how it affects users and business Think feedback, iteration, and learning are part of the job - not afterthoughts Requirements Bachelor’s or Master’s degree in Computer Science, Engineering, or related field 4–6 years of experience in AI engineering, with production deployment experience Strong Python skills is a MUST Deep familiarity with ML frameworks (e.g., TensorFlow, PyTorch, Scikit-learn) Experience working on real-world AI applications (e.g., risk scoring, recommendation, NLP, etc.) Experience mentoring engineers and collaborating across functions Strong communication skills - able to work cross-functionally and provide technical leadership Must be based in Indonesia and able to work remotely with Malaysia HQ Nice to Have Experience with MLOps tooling (MLflow, Airflow, Docker, GCP/AWS) Familiarity with model explainability, fairness, or responsible AI practices Background in startup or high-growth tech environments Exposure to building internal AI tools, frameworks, or reusable components What You’ll Get Competitive salary and performance bonuses Fully remote, flexible work setup from anywhere in Indonesia High ownership, visible impact, and direct reporting to the Head of AI Fast career growth in a company scaling across ASEAN Opportunity to lead a lean, smart team solving meaningful problems Access to cross-border collaboration and regional product exposure About BJAK BJAK is Southeast Asia’s largest digital insurance platform, helping millions access transparent and affordable financial protection. Headquartered in Malaysia and operating across Thailand, Taiwan, and Japan, we simplify financial products using AI, automation, and smart systems, making them accessible, fast, and fair. Join us to shape the future of AI-driven finance. If you’re ready to build, lead, and scale AI that matters - and grow with a company that moves fast and thinks big - we’d love to hear from you.",airflow;aws;communication;docker;fraud detection;gcp;leadership;machine learning;mlops;monitoring;nlp;python;pytorch;risk modeling;scikit-learn;tensorflow
Machine Learning Engineer,PT Prima Vista Solusi,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/machine-learning-engineer-at-pt-prima-vista-solusi-4331344264?position=5&pageNum=7&refId=coILZsHqzI7d%2FJg4ErNnSw%3D%3D&trackingId=1FCpzt4MY2%2BiVi7dG4v6ZA%3D%3D,"Design, develop, and deploy cutting-edge LLMs for diverse NLP applications. Optimize and fine-tune large-scale language models using frameworks like TensorFlow, PyTorch, or JAX. Research and implement advancements in LLMs, including transformer architectures and reinforcement learning techniques. Work closely with data scientists, software engineers, and product managers to integrate LLMs into production systems. Build and maintain scalable machine learning pipelines for training and inference. Ensure LLMs are efficient, high-performing, and scalable for real-world applications. Evaluate AI models using key NLP metrics and refine them based on experimental results. Stay updated with the latest AI research and contribute to open-source projects where relevant. Implement responsible AI principles, including fairness, explainability, and ethical considerations. Document AI model architectures, training methodologies, and deployment strategies. Minimum Qualifications Bachelor's, Master's in Computer Science, Artificial Intelligence, Machine Learning, or a related field. Minimum 3-5 years of experience in machine learning, deep learning, or natural language processing roles. Strong proficiency in Python and experience with ML frameworks like TensorFlow, PyTorch, or JAX. Hands-on experience with large-scale language models, including transformers, GPT-based models, and BERT-style architectures. Experience with cloud platforms (AWS, Google Cloud, Azure) and ML model deployment. Knowledge of MLOps practices, including model versioning, monitoring, and automation. Experience with large-scale datasets, data preprocessing, and distributed computing frameworks (e.g., Spark, Ray). Solid understanding of deep learning architectures, optimization techniques, and reinforcement learning. Strong problem-solving skills and ability to conduct independent research. Excellent collaboration and communication skills for cross-functional teamwork. Experience with prompt engineering, fine-tuning LLMs, and retrieval-augmented generation (RAG) is a must. Contributions to AI research publications or open-source projects are highly desirable.",aws;azure;bert;communication;data preprocessing;deep learning;google cloud;gpt;jax;machine learning;mlops;model deployment;monitoring;natural language processing;nlp;python;pytorch;rag;spark;teamwork;tensorflow;transformer
Data Scientist,cmlabs,"Malang, East Java, Indonesia",https://id.linkedin.com/jobs/view/data-scientist-at-cmlabs-4290554822?position=6&pageNum=7&refId=coILZsHqzI7d%2FJg4ErNnSw%3D%3D&trackingId=dcI3Isqwt6jdlCy38JGYZw%3D%3D,"DATA JUNIOR INTERNSHIP Updated 2023-05-22 Copy link to share Job Link POSITION Data Scientist TEAM Data POSITION LEVEL Junior POSITION TYPE Internship POSITION LOCATION Malang, Indonesia OUTLINE Company Description Qualification Job Description Skills Tools Benefits Recruitment Pipeline Company Description cmlabs is a brand under PT CMLABS INDONESIA DIGITAL, specializes in the SEO field and was established in 2019. cmlabs located in two big cities in Indonesia, Jakarta and Malang. This company was initiated with an idea to help companies or enterprises increase the visibility of their brand on the internet. cmlabs used to stand for Content Marketing Labs, but now cmlabs is a new term as SEO product and services which is called Software as a Service (SaaS). cmlabs serve users in SEO Consultant, Content Writing, Content Marketing, and also have a product which is SERPs Tracker. Besides the services and product, SEO Tools also available, users who are having SEO and marketing activities can utilize the tools with no cost for 24 hours. cmlabs will expand to a bigger market to present SEO product and serve SEO activities on a global scale for enterprises Job Description Analyze the company database for optimization and improvement of the company's business Filter and cleanse unstructured (or ambiguous) data into usable data sets that can be analyzed to extract insights and improve business processes. Ensure the data are captured correctly so that they can be processed. Assess the effectiveness and accuracy of new data sources and data collection Develop algorithms Qualification Fresh graduate and senior year, students are welcome Understanding of machine-learning and operations research Strong math skills Teamwork and communication skills Interested in startup culture Able to do 3 months internship Personality Traits Result oriented Critical thinking Analytical thinking Data-Driven Have a good endurance Fast learned Tend to detail Structural Skills Analytical Programming Statistics Tools SEO tools Google Workspace Google Analytics R Studio Google Search Console Company Perks Sharing session We want to make sure that everyone can grow in cmlabs. We are driven by the idea that knowledgeable employees are the biggest assets in the company. Peer learning Peer learning enables you to collaborate with your colleagues and learn new skills. Any collaboration of peers can be considered as peer learning and we believe it will narrow knowledge gaps between the employees. Webinar Through webinar, we can reach out to communities outside cmlabs. As we reach out to more people in professional settings, we also sharpen our skills in public speaking. Competitive compensation We care about our employees' financial well-being, which is why we make sure it meets their expectations. Regular bonus and equity refresh opportunity The more you perform well, the more bonus you will receive. Six-month salary equity analysis and adjustment We evaluate everyone's performance every six months to adjust and possibly raise the salary. Hybrid Working Environment We use hybrid work in accordance with the company's arrangement. Flexible Working Hours We encourage our employees to take advantage of flexible working hours. They can choose when they want to work the most during the day. This is an effective way to increase work-life balance. Paid leave Annual leave, sickness, and any special events are considered paid leave. We want our employees to take time off so that they can come back with other valuable opportunities. Unpaid leave In certain conditions, unpaid leave is granted to our employees. We make sure everyone has their rights. Part-time We have a part-time program that can benefit students or anyone who wants to participate in achieving our mission. Employment insurance and health insurance We provide comprehensive healthcare and employment insurance for a better quality of life. Comfort office To increase productivity, we provide a cozy office, complete with a garden and other comfortable facilities. Breakfast and lunch Working in a pleasant atmosphere might not be enough. You probably need something more. Food will be perfect to cheer up everyone in the office. Sharing session We want to make sure that everyone can grow in cmlabs. We are driven by the idea that knowledgeable employees are the biggest assets in the company. Peer learning Peer learning enables you to collaborate with your colleagues and learn new skills. Any collaboration of peers can be considered as peer learning and we believe it will narrow knowledge gaps between the employees. Webinar Through webinar, we can reach out to communities outside cmlabs. As we reach out to more people in professional settings, we also sharpen our skills in public speaking. Competitive compensation We care about our employees' financial well-being, which is why we make sure it meets their expectations. Regular bonus and equity refresh opportunity The more you perform well, the more bonus you will receive. Six-month salary equity analysis and adjustment We evaluate everyone's performance every six months to adjust and possibly raise the salary. Hybrid Working Environment We use hybrid work in accordance with the company's arrangement. Flexible Working Hours We encourage our employees to take advantage of flexible working hours. They can choose when they want to work the most during the day. This is an effective way to increase work-life balance. Paid leave Annual leave, sickness, and any special events are considered paid leave. We want our employees to take time off so that they can come back with other valuable opportunities. Unpaid leave In certain conditions, unpaid leave is granted to our employees. We make sure everyone has their rights. Part-time We have a part-time program that can benefit students or anyone who wants to participate in achieving our mission. Employment insurance and health insurance We provide comprehensive healthcare and employment insurance for a better quality of life. Comfort office To increase productivity, we provide a cozy office, complete with a garden and other comfortable facilities. Breakfast and lunch Working in a pleasant atmosphere might not be enough. You probably need something more. Food will be perfect to cheer up everyone in the office. Recruitment Pipeline Application Review In this stage, your CV will be screened, assessed, and determined whether you pass or not. Pre-assessment Test The pre-assessment test is a test to assess your skills and knowledge about the position that you’re applying for. HR Interview In this interview, our HR will assess your personality and to understand whether you're the right fit for the position that you’re applying for or not. User Interview Here, the user will conduct the interview to find out how much you know about the technical skills of the job and the chemistry between the user and you. Final Interview The final job interview is the end of the interview process. It's likely your last point of contact with interviewers before you find out whether or not you will be getting a job offer.",communication;critical thinking;data scientist;r;teamwork
"Staff Machine Learning Engineer (India based, relocation provided)",Agoda,"Bali, Indonesia",https://id.linkedin.com/jobs/view/staff-machine-learning-engineer-india-based-relocation-provided-at-agoda-4302587821?position=7&pageNum=7&refId=coILZsHqzI7d%2FJg4ErNnSw%3D%3D&trackingId=yllaovxVuarxhm4wEZ636g%3D%3D,"About Agoda Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with a global network of 4.7M hotels and holiday properties worldwide, plus flights, activities, and more. Based in Asia and part of Booking Holdings, our 7,100+ employees representing 95+ nationalities in 27 markets foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Our Purpose - Bridging the World Through Travel We believe travel allows people to enjoy, learn and experience more of the amazing world we live in. It brings individuals and cultures closer together, fostering empathy, understanding and happiness. We are a skillful, driven and diverse team from across the globe, united by a passion to make an impact. Harnessing our innovative technologies and strong partnerships, we aim to make travel easy and rewarding for everyone. Agoda is an online travel booking platform for accommodation, flights, and more. We build and deploy cutting edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 4,000+ talents coming from 90+ different nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enabling our customers to experience the world. Get to Know Our Team The Engineering department oversees all Agoda’s ML and software related requirements. Our goal is to enable and increase Agoda’s business through creative approaches and the implementation of powerful resources such as operational and analytical databases, ML driven solutions, queue systems and data monitoring tools. We hire the brightest minds from around the world to take on this challenge and equip them with the knowledge and tools that contribute to their personal growth and success while supporting our company’s culture of diversity and experimentation. The role the engineering team plays at Agoda is critical as business users, product managers, and many others rely on us to empower their decision making. We are equally dedicated to our customers by improving their search experience with faster results and protecting them from any fraudulent activities. Data is interesting only when you have enough of it, and we have plenty. This is what drives up the challenge as part of the ML engineering squad, but also the reward. We work across structured and non-structured data at scale. For example, our current ML models process millions of images every day to try and enhance the experience that our users get from our app. Why Agoda Engineering Team (ML role)? Our engineering teams are at the intersection of business analytics, ml engineering, data warehousing and software engineering. Our job involves dealing with distributed systems, stream processing, ml modeling and computation at tens of PB Scale. We focus on software engineering related to data replication, storage, centralized computation, and Data API’s. By providing our users with ML products/tools, shared frameworks, and ML services, we enable our company to validate strategic decisions, make smarter choices, and react to the fast-changing world. We are a small but passionate team with people from different nationalities working together on a single goal. In this Role, you will get to: Lead the team technically in improving scalability, stability, accuracy, speed and efficiency of our existing ML systems and processes. Build, administer and scale ML processing pipelines. Be comfortable navigating the following technology stack: Python3, Pyspark, scripting (Bash/Python), Hadoop, SQL, S3 etc. Should be able to understand internals of ML models such as Random Forest, CNN, Regression models, etc Design, build, test and deploy new libraries, frameworks or full systems for our core systems while keeping to the highest standards of testing and code quality. Work with experienced engineers and product owners to identify and build tools to automate many large-scale data management / analysis tasks. We believe in end-to-end ownership; this role will involve taking ML models to production at a scale. What You’ll need to Succeed: Bachelor’s degree in computer science /information systems/engineering/related field 8+ years of experience in software engineering with a minimum of 4+ years in ML Good experience in Pyspark Expert level understanding of Python with design patterns and object-oriented programming. Experience debugging and reasoning about production issues is desirable. A good understanding of data architecture principles preferred. Any other experience with Big Data technologies / tools SQL experience Analytical problem-solving capabilities & experience. Systems administration skills in Linux A strong engineering driven mindset will be required to succeed in this role. It’s great if you have: Good understanding of Hadoop ecosystems Experience working with Open-source products Experience with Scala development Working in an agile environment using test driven methodologies Benefits Hybrid Working Model WFH Set Up Allowance 30 Days of Remote Working from anywhere globally every year Employee discount for accommodation globally Global team of 90+ nationalities 40+ offices and 25+ countries Annual CSR / Volunteer Time off Benevity Subscription for employee donations Volunteering opportunities globally Free Headspace subscription Free Odilo & Udemy subscriptions Access to Employee Assistance Program (third party for personal and workplace support) Enhanced Parental Leave Life, TPD & Accident Insurance #telaviv #jerusalem #IT #ENG #4 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #sydney #melbourne #perth #toronto #vancouver #montreal #prague #Brno #Ostrava #cairo #alexandria #giza #estonia #paris #berlin #munich #hamburg #stuttgart #cologne #frankfurt #budapest #bali #dublin #telaviv #milan #rome #venice #florence #naples #turin #palermo #bologna #osaka #malta #amsterdam #oslo #warsaw #krakow #alrayyan #riyadh #jeddah #mecca #medina #singapore #seoul #barcelona #madrid #stockholm #zurich #taipei #tainan #taichung #kaohsiung #bangkok #Phuket #istanbul #london #manchester  #edinburgh #hcmc #hanoi #lodz #wroclaw #poznan #katowice #rio #salvador #newdelhi #bangalore #bandung #yokohama #nagoya #okinawa #fukuoka #jerusalem #IT #4 #bangalore #delhi #hyderabad #pune #singapore #beijing #shanghai #shenzhen #tokyo #seoul #hongkong #taipei #kualalumpur #jakarta #hochiminh #hochiminhcity #manila #instanbul #makati #dubai #riyadh #gurgaon #noida Discover More About Working At Agoda Agoda Careers https://careersatagoda.com Facebook https://www.facebook.com/agodacareers/ LinkedIn https://www.linkedin.com/company/agoda YouTube https://www.youtube.com/agodalife Equal Opportunity Employer At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. Disclaimer We do not accept any terms or conditions, nor do we recognize any agency’s representation of a candidate, from unsolicited third-party or agency submissions. If we receive unsolicited or speculative CVs, we reserve the right to contact and hire the candidate directly without any obligation to pay a recruitment fee.",agile;bash;business analytics;cnn;distributed systems;hadoop;linux;monitoring;privacy;pyspark;python;random forest;react;s3;scala;scalability;sql;testing
Backend Developer (Java),PT. Intikom Berlian Mustika,"Jakarta, Indonesia",https://id.linkedin.com/jobs/view/backend-developer-java-at-pt-intikom-berlian-mustika-4336766433?position=8&pageNum=7&refId=coILZsHqzI7d%2FJg4ErNnSw%3D%3D&trackingId=dEt4RQSfC6rzUG%2FwrNPExQ%3D%3D,"Responsibilities Design, develop and maintain high-quality Java applications at the company. Collaborate with teams in other departments to identify and prioritise requirements. Develop best practices for the company and participate in code reviews with the team and other stakeholders. Conduct technical analysis to arrive at solutions and create technological artefacts in response to production issues. Qualifications A Bachelor’s or Master’s degree in software engineering, computer science, or a related field. 3+ years of experience in software development, database management, or a role with similar responsibilities. Strong knowledge of Java languages and web development frameworks like Springboot, Spring, Hibernate, Struts and JDK8. Required skills and qualifications Strong analytical and problem-solving skills with organisational capabilities. Experience with DevOps practices and tools (Git, Jenkins, and Docker). Excellent problem-solving and analytical skills with good teamwork capabilities.",devops;docker;git;java;jenkins;teamwork
"Staff Machine Learning Engineer (India based, relocation provided)",Agoda,"Bandung, West Java, Indonesia",https://id.linkedin.com/jobs/view/staff-machine-learning-engineer-india-based-relocation-provided-at-agoda-4302595599?position=9&pageNum=7&refId=coILZsHqzI7d%2FJg4ErNnSw%3D%3D&trackingId=qPMsW8cWvuxtpm0cRuIO8g%3D%3D,"About Agoda Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with a global network of 4.7M hotels and holiday properties worldwide, plus flights, activities, and more. Based in Asia and part of Booking Holdings, our 7,100+ employees representing 95+ nationalities in 27 markets foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world. Our Purpose - Bridging the World Through Travel We believe travel allows people to enjoy, learn and experience more of the amazing world we live in. It brings individuals and cultures closer together, fostering empathy, understanding and happiness. We are a skillful, driven and diverse team from across the globe, united by a passion to make an impact. Harnessing our innovative technologies and strong partnerships, we aim to make travel easy and rewarding for everyone. Agoda is an online travel booking platform for accommodation, flights, and more. We build and deploy cutting edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 4,000+ talents coming from 90+ different nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enabling our customers to experience the world. Get to Know Our Team The Engineering department oversees all Agoda’s ML and software related requirements. Our goal is to enable and increase Agoda’s business through creative approaches and the implementation of powerful resources such as operational and analytical databases, ML driven solutions, queue systems and data monitoring tools. We hire the brightest minds from around the world to take on this challenge and equip them with the knowledge and tools that contribute to their personal growth and success while supporting our company’s culture of diversity and experimentation. The role the engineering team plays at Agoda is critical as business users, product managers, and many others rely on us to empower their decision making. We are equally dedicated to our customers by improving their search experience with faster results and protecting them from any fraudulent activities. Data is interesting only when you have enough of it, and we have plenty. This is what drives up the challenge as part of the ML engineering squad, but also the reward. We work across structured and non-structured data at scale. For example, our current ML models process millions of images every day to try and enhance the experience that our users get from our app. Why Agoda Engineering Team (ML role)? Our engineering teams are at the intersection of business analytics, ml engineering, data warehousing and software engineering. Our job involves dealing with distributed systems, stream processing, ml modeling and computation at tens of PB Scale. We focus on software engineering related to data replication, storage, centralized computation, and Data API’s. By providing our users with ML products/tools, shared frameworks, and ML services, we enable our company to validate strategic decisions, make smarter choices, and react to the fast-changing world. We are a small but passionate team with people from different nationalities working together on a single goal. In this Role, you will get to: Lead the team technically in improving scalability, stability, accuracy, speed and efficiency of our existing ML systems and processes. Build, administer and scale ML processing pipelines. Be comfortable navigating the following technology stack: Python3, Pyspark, scripting (Bash/Python), Hadoop, SQL, S3 etc. Should be able to understand internals of ML models such as Random Forest, CNN, Regression models, etc Design, build, test and deploy new libraries, frameworks or full systems for our core systems while keeping to the highest standards of testing and code quality. Work with experienced engineers and product owners to identify and build tools to automate many large-scale data management / analysis tasks. We believe in end-to-end ownership; this role will involve taking ML models to production at a scale. What You’ll need to Succeed: Bachelor’s degree in computer science /information systems/engineering/related field 8+ years of experience in software engineering with a minimum of 4+ years in ML Good experience in Pyspark Expert level understanding of Python with design patterns and object-oriented programming. Experience debugging and reasoning about production issues is desirable. A good understanding of data architecture principles preferred. Any other experience with Big Data technologies / tools SQL experience Analytical problem-solving capabilities & experience. Systems administration skills in Linux A strong engineering driven mindset will be required to succeed in this role. It’s great if you have: Good understanding of Hadoop ecosystems Experience working with Open-source products Experience with Scala development Working in an agile environment using test driven methodologies Benefits Hybrid Working Model WFH Set Up Allowance 30 Days of Remote Working from anywhere globally every year Employee discount for accommodation globally Global team of 90+ nationalities 40+ offices and 25+ countries Annual CSR / Volunteer Time off Benevity Subscription for employee donations Volunteering opportunities globally Free Headspace subscription Free Odilo & Udemy subscriptions Access to Employee Assistance Program (third party for personal and workplace support) Enhanced Parental Leave Life, TPD & Accident Insurance #telaviv #jerusalem #IT #ENG #4 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #sydney #melbourne #perth #toronto #vancouver #montreal #prague #Brno #Ostrava #cairo #alexandria #giza #estonia #paris #berlin #munich #hamburg #stuttgart #cologne #frankfurt #budapest #bali #dublin #telaviv #milan #rome #venice #florence #naples #turin #palermo #bologna #osaka #malta #amsterdam #oslo #warsaw #krakow #alrayyan #riyadh #jeddah #mecca #medina #singapore #seoul #barcelona #madrid #stockholm #zurich #taipei #tainan #taichung #kaohsiung #bangkok #Phuket #istanbul #london #manchester  #edinburgh #hcmc #hanoi #lodz #wroclaw #poznan #katowice #rio #salvador #newdelhi #bangalore #bandung #yokohama #nagoya #okinawa #fukuoka #jerusalem #IT #4 #bangalore #delhi #hyderabad #pune #singapore #beijing #shanghai #shenzhen #tokyo #seoul #hongkong #taipei #kualalumpur #jakarta #hochiminh #hochiminhcity #manila #instanbul #makati #dubai #riyadh #gurgaon #noida Discover More About Working At Agoda Agoda Careers https://careersatagoda.com Facebook https://www.facebook.com/agodacareers/ LinkedIn https://www.linkedin.com/company/agoda YouTube https://www.youtube.com/agodalife Equal Opportunity Employer At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics. We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy. Disclaimer We do not accept any terms or conditions, nor do we recognize any agency’s representation of a candidate, from unsolicited third-party or agency submissions. If we receive unsolicited or speculative CVs, we reserve the right to contact and hire the candidate directly without any obligation to pay a recruitment fee.",agile;bash;business analytics;cnn;distributed systems;hadoop;linux;monitoring;privacy;pyspark;python;random forest;react;s3;scala;scalability;sql;testing
Lead Data Scientist – Synthetic Systems,Populix,"Jakarta, Jakarta, Indonesia",https://id.linkedin.com/jobs/view/lead-data-scientist-%E2%80%93-synthetic-systems-at-populix-4279653092?position=10&pageNum=7&refId=coILZsHqzI7d%2FJg4ErNnSw%3D%3D&trackingId=Vh%2BKHbyrBOPqpRUG4q1J%2Fg%3D%3D,"About us: Populix is a consumer insights platform that helps businesses connect with its database of respondents and provides them with insights to better understand the preferences of Indonesian consumers. Populix has a pool of over 1,000,000 diverse, readily accessible, and highly qualified respondents across Indonesia. Its products range from intensive research studies to simple surveys and can be arranged on a project or subscription basis. Focusing on Indonesian consumers being super sticky to their phones, Populix facilitates a diverse range of data collection methods via its mobile app. About the Role: Populix is building the future of AI-powered market research, combining structured data, unstructured insights, and generative AI into a seamless research intelligence platform. We're looking for a Lead Data Scientist to help drive that vision forward, someone who can spearhead the development of simulation systems and automation pipelines, while actively supporting the Head of Data Science in shaping our AI research strategy. This role will be at the forefront of building simulation modeling, scaling automation for text and audio-based survey data, and translating our research into whitepapers that position Populix as a thought leader in the region. You'll also play a key role in advancing our use of retrieval-augmented generation (RAG) and modular AI architectures to deliver insights that are fast, accurate, and contextualized. Key Responsibilities: Lead the design and implementation of behavioral simulation responses and demographic patterns using generative models, statistical modeling, and controlled simulations Collaborate with the research and marketing teams to create simulation-driven whitepapers and internal studies, helping communicate the value of synthetic insight across use cases like campaign testing, segmentation, and hypothetical trends Drive automation of research workflows that involve open-ended responses and audio data, including pipelines for transcription, classification, summarization, and sentiment analysis Work with the Head of Data Science to translate high-level product and research strategy into technical roadmaps, experiment plans, and model architecture decisions Help scale our AI insight engine by contributing to Retrieval-Augmented Generation (RAG) workflows and collaborating with LLM engineers on modular pipelines for context-rich output generation Collaborate closely with engineers, designers, and product teams to ship robust ML-powered tools into production across the Populix platform Provide mentorship to other data scientists, sharing knowledge, reviewing modeling work, and helping maintain a culture of experimentation, reproducibility, and ethical AI Required Qualifications: Master’s degree required, preferably in Computer Science, Statistics, Data Science, or a related quantitative field; PhD is a strong plus 5+ years of experience in data science or applied machine learning, including at least 1 year in a technical leadership role Deep experience in generative modeling (e.g., GANs, VAEs), simulation, or behavioral data modeling, with a strong grounding in statistics and hypothesis testing Hands-on experience with Retrieval-Augmented Generation (RAG) architectures and knowledge integration with LLMs Solid programming skills in Python and experience with tools like LangGraph, LangSmith, scikit-learn, PyTorch, Hugging Face, or equivalent frameworks Familiarity with both structured (e.g., survey data) and unstructured (e.g., audio, text) data workflows, including preprocessing, feature extraction, and integration into insight pipelines Experienced in creating ideas and coding them into effective AI-driven solutions to real-world problems Strong communication skills and the ability to translate complex modeling approaches into product or research value Preferred Qualifications: Prior experience in market research, behavioral analytics, or social data modeling Exposure to speech processing, voice-to-text systems, and sentiment detection from audio or conversational data Knowledge of synthetic data generation ethics, validation strategies, and mixed-method evaluation Experience working with cloud-based analytics environments and orchestration tools (e.g., BigQuery, Airflow, Kubeflow, MLflow) Experienced in working as an individual contributor Powered by JazzHR pWMIc2dRrQ",airflow;bigquery;communication;data modeling;data scientist;generative ai;hypothesis testing;leadership;llm;machine learning;python;pytorch;rag;scikit-learn;segmentation;sentiment analysis;testing
